{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Nhập thư viện và đọc dữ liệu từ file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import dython\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "df = pd.read_csv(\"data.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Khám phá dữ liệu (Exploratory Data Analysis - EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### a. Tóm tắt thông tin dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "cái df này nó chỉ có cột target là cat thôi vì trên uci nó đã label encode r lọc ra thành mấy cột integer r nên h đi tìm lại để tìm tương quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=[\"object\"])\n",
    "print(cat_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['number'])\n",
    "print(num_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_like = [col for col in df.columns if df[col].nunique() < 50]\n",
    "print(cat_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiative_columns = [\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (credited)',\n",
    "    'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (without evaluations)',\n",
    "    'Curricular units 2nd sem (credited)',\n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (without evaluations)',\n",
    "    'Unemployment rate',\n",
    "    'Inflation rate',\n",
    "    'GDP'\n",
    "]\n",
    "\n",
    "cat_columns = [col for col in cat_like if col not in quantiative_columns]\n",
    "ordinal_column = [\"Application order\"]\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Kiểm tra số lượng bản ghi, số lượng biến số, kiểu dữ liệu của từng biến.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Xử lý dữ liệu thiếu, dữ liệu trùng lặp (nếu có).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### b. Phân tích thống kê mô tả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Tính các thống kê như trung bình, trung vị, độ lệch chuẩn, tứ phân vị.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.drop(columns=cat_columns)\n",
    "df_numeric.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Histogram split by target\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x='Admission grade',\n",
    "    hue='Target',        # separates Dropout vs Graduate\n",
    "    bins=20,             # adjust for clarity\n",
    "    kde=True,            # optional: overlay density\n",
    "    stat='density',      # normalize for comparison\n",
    "    palette=['red', 'green','blue'],\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "plt.title('Admission grade distribution by Target')\n",
    "plt.xlabel('Admission grade')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Trực quan hoá bằng các biểu đồ phù hợp (ít nhất 3 loại biểu đồ) để nhận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a countplot:\n",
    "# x-axis: The outcome (Target)\n",
    "# hue: The secondary variable used to group the bars (Attendance Status)\n",
    "# palette: Uses the same color scheme as the previous example (reds/greens) for consistency\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x='Target',\n",
    "    hue='Daytime/evening attendance\\t',\n",
    "    palette={'green','red'},\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# --- 3. CUSTOMIZE PLOT AESTHETICS ---\n",
    "plt.title('Student Outcome (Target) by Attendance Status', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Student Outcome', fontsize=14)\n",
    "plt.ylabel('Count of Students', fontsize=14)\n",
    "plt.legend(title='Attendance Status', title_fontsize='12', fontsize='10')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "attendance_col = 'Daytime/evening attendance\\t'  # keep the tab if it's in the column name\n",
    "target_col = 'Target'\n",
    "\n",
    "# Count occurrences\n",
    "counts = df.groupby([attendance_col, target_col]).size().reset_index(name='count')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=counts, x=attendance_col, y='count', hue=target_col)\n",
    "plt.xlabel('Attendance Type (0=Daytime, 1=Evening)')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.title('Attendance Type vs Final Target')\n",
    "plt.legend(title='Target')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "this data makes sense specially for this dataset since this is A dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies. \n",
    "\n",
    "i.e. they have jobs in the day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_col = 'Daytime/evening attendance\\t'\n",
    "target_col = 'Target'\n",
    "\n",
    "categories = ['Dropout', 'Enrolled', 'Graduate']\n",
    "\n",
    "daytime_counts = df[df[attendance_col] == 0][target_col].value_counts().reindex(categories)\n",
    "evening_counts = df[df[attendance_col] == 1][target_col].value_counts().reindex(categories)\n",
    "\n",
    "# Create two side-by-side pie charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "axes[0].pie(daytime_counts, labels=daytime_counts.index, autopct='%1.1f%%', startangle=90, colors=[\"#ff0000\",'#8da0cb','#66c2a5'])\n",
    "axes[0].set_title('Daytime Attendance')\n",
    "\n",
    "axes[1].pie(evening_counts, labels=evening_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff0000','#8da0cb','#66c2a5'])\n",
    "axes[1].set_title('Evening Attendance')\n",
    "\n",
    "plt.suptitle('Target Distribution by Attendance Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "this one shows percantage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Same thing but for scholarship (this should be obvious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_col = 'Scholarship holder'  # keep the tab if it's in the column name\n",
    "target_col = 'Target'\n",
    "\n",
    "# Count occurrences\n",
    "counts = df.groupby([var_col, target_col]).size().reset_index(name='count')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=counts, x=var_col, y='count', hue=target_col)\n",
    "plt.xlabel('Scholarship holder (0=No, 1=Yes)')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.title('Scholarship Type vs Final Target')\n",
    "plt.legend(title='Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_col = 'Scholarship holder'  \n",
    "target_col = 'Target'\n",
    "\n",
    "categories = ['Dropout', 'Enrolled', 'Graduate']\n",
    "\n",
    "no = df[df[var_col] == 0][target_col].value_counts().reindex(categories)\n",
    "yes = df[df[var_col] == 1][target_col].value_counts().reindex(categories)\n",
    "\n",
    "# Create two side-by-side pie charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "axes[0].pie(no, labels=no.index, autopct='%1.1f%%', startangle=90, colors=[\"#ff0000\",'#8da0cb','#66c2a5'])\n",
    "axes[0].set_title('Non scholarship holders')\n",
    "\n",
    "axes[1].pie(yes, labels=yes.index, autopct='%1.1f%%', startangle=90, colors=['#ff0000','#8da0cb','#66c2a5'])\n",
    "axes[1].set_title('Scholarship holders')\n",
    "\n",
    "plt.suptitle('Target Distribution by Scholarship Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### c. Phát hiện dữ liệu ngoại lai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Sử dụng IQR (Interquartile Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "df_numeric.boxplot(rot=90)  # rot=90 to rotate x-axis labels\n",
    "plt.title(\"Boxplots of All Numeric Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "**investigating gdp, inflation and unemployment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['GDP', 'Unemployment rate', 'Inflation rate']]\n",
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Knowing that the data comes from the Instituto Politécnico de Portalegre (IPP) in Portugal directly confirms two key points that validate our previous investigation:\n",
    "\n",
    "Country: The economic data is relevant to Portugal.\n",
    "\n",
    "Context: The data is from a Portuguese polytechnic institute during a specific time period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "| Metric            | Range (Min to Max) | Confirmed Context                                                                 | Conclusion                                           |\n",
    "|------------------|-------------------|----------------------------------------------------------------------------------|----------------------------------------------------|\n",
    "| Unemployment Rate | 7.6% to 16.2%     | Matches the severe economic crisis and subsequent recovery in Portugal (roughly 2008–2018). | Plausible. The highest values are likely accurate historical peaks. |\n",
    "| Inflation Rate    | -0.8% to 3.7%     | Matches Portugal's largely stable, low-inflation environment during that period, including some deflationary dips. | Plausible. Very stable and reliable data.         |\n",
    "| GDP               | -4.06 to 3.51     | Matches Portugal's sharp recessionary decline followed by years of recovery growth. | Plausible. Represents real economic volatility.   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "phương pháp xử lý đề xuất (cho mấy cột trên với lại mấy cái course)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "***!!!Square Root Transformation!!!***\n",
    "might or might or have to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "You only transform the distribution (log/square root) for features that are highly skewed (like GDP and Curricular Units). You must apply scaling to every continuous numeric column to ensure no single variable dominates your model due to its large value range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "***NHẬN XÉT TỔNG QUAN SO FAR***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## 2. Phân tích phân phối xác suất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### Chọn ít nhất hai biến số quan trọng và kiểm tra xem nó có tuân theo phân phối xác suất nào không (chuẩn, Poisson, exponential…) sử dụng biểu đồ phù hợp để minh hoạ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Application order\"\n",
    "data = df[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Admission grade\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Age at enrollment\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Curricular units 1st sem (grade)\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Curricular units 2nd sem (grade)\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## 3. Kiểm định giả thuyết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày các kiểm định thống kê sau: t-test, Chi-square và ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### b. Đề xuất hai câu hỏi nghiên cứu có thể kiểm định bằng dữ liệu cho bộ dữ liệu đã chọn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "câu hỏi: giới tính khác nhau có ảnh hưởng đến cái dropout rate hay ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Tạo bảng tần số (contingency table)\n",
    "table = pd.crosstab(df['Gender'], df['Target'])\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, expected = chi2_contingency(table)\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Expected frequencies:\\n\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): Giới tính và kết quả học tập không liên quan (độc lập)\n",
    "\n",
    "Alternative hypothesis (H1): Có sự phụ thuộc giữa giới tính và kết quả học tập\n",
    "\n",
    "Nếu p < 0.05 → bác bỏ H0 → có sự khác biệt có ý nghĩa\n",
    "\n",
    "Nếu p >= 0.05 → không bác bỏ H0 → không có bằng chứng về sự khác biệt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Vì p << 0.05, chúng ta bác bỏ H0 → kết luận:\n",
    "\n",
    "Có sự khác biệt rất rõ ràng về kết quả học tập giữa nam và nữ. Giới tính và Target không độc lập trong dữ liệu này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_norm = table.div(table.sum(axis=1), axis=0)  # chuyển sang tỉ lệ %\n",
    "table_norm.plot(kind='bar', stacked=True, figsize=(8,5), colormap='Set2')\n",
    "\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xlabel(\"Gender (0=Male, 1=Female)\")\n",
    "plt.title(\"Target distribution by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Bảng tỉ lệ %\n",
    "table_percent = table.div(table.sum(axis=1), axis=0) * 100\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(table_percent, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Gender (0=Male, 1=Female)\")\n",
    "plt.title(\"Heatmap of Target distribution by Gender (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data=df, x='Admission grade', hue='Gender', \n",
    "             bins=20, kde=True, palette=['blue','orange'], alpha=0.6, stat='density')\n",
    "\n",
    "plt.title('Distribution of Admission Grade by Gender')\n",
    "plt.xlabel('Admission Grade')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Gender', labels=['Female','Male'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "wowza! kết quả cho thấy có sự chênh lệch rõ ràng giữa hai giới tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "#### Kiểm định khác biệt độ tuồi giữa các nhóm target bằng anova ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "anova cần mấy biến tuân theo phân phối chuẩn, nên t đi check coi chuẩn ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "from scipy.stats import levene\n",
    "\n",
    "groups = df.groupby('Target')['Age at enrollment']\n",
    "\n",
    "for name, group_data in groups:\n",
    "    stat, p = shapiro(group_data.dropna())  # drop NA values\n",
    "    print(f\"{name}: W={stat:.3f}, p={p:.3f}\")\n",
    "\n",
    "groups = [group.dropna() for name, group in df.groupby('Target')['Age at enrollment']]\n",
    "\n",
    "stat, p = levene(*groups)\n",
    "print(f\"Levene’s test: W={stat:.3f}, p={p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "⚠️ This violates the normality assumption for ANOVA.\n",
    "\n",
    "⚠️ This violates the homogeneity of variance assumption for ANOVA.\n",
    "\n",
    "Since both normality and equal variance assumptions are violated, one-way ANOVA is NOT appropriate here.\n",
    "\n",
    "✅ Correct approach:\n",
    "Use a non-parametric alternative like Kruskal-Wallis test, which does not assume normality or equal variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "dropout_age = df[df['Target']=='Dropout']['Age at enrollment']\n",
    "enrolled_age = df[df['Target']=='Enrolled']['Age at enrollment']\n",
    "graduate_age = df[df['Target']=='Graduate']['Age at enrollment']\n",
    "\n",
    "stat, p = kruskal(dropout_age, enrolled_age, graduate_age)\n",
    "print(f\"Kruskal-Wallis test: H={stat:.3f}, p={p:.3e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "Since p << 0.05, you reject the null hypothesis. This means there is a statistically significant difference between at least one pair of your groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "Minh họa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for plotting\n",
    "plot_df = df[['Target', 'Age at enrollment']].dropna()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.violinplot(x='Target', y='Age at enrollment', data=plot_df, palette=\"Set3\")\n",
    "plt.title(\"Age at Enrollment by Target Group\")\n",
    "plt.ylabel(\"Age at Enrollment\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "Kết luận: Dữ liệu cho thấy mối quan hệ nghịch đảo giữa độ tuổi nhập học và khả năng tốt nghiệp. Về mặt thống kê, những sinh viên nhập học ở độ tuổi truyền thống sớm hơn có khả năng hoàn thành chương trình học cao hơn nhiều so với những sinh viên nhập học muộn hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "## 4. Phân tích tương quan giữa các biến"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày hệ số tương quan Pearson và Spearman."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "Pearson correlation coefficient (PCC) is a correlation coefficient that measures linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations; thus, it is essentially a normalized measurement of the covariance, such that the result always has a value between −1 and 1. As a simple example, one would expect the age and height of a sample of children from a school to have a Pearson correlation coefficient significantly greater than 0, but less than 1 (as 1 would represent an unrealistically perfect correlation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "Spearman's rank correlation coefficient or Spearman's ρ is a number ranging from -1 to 1 that indicates how strongly two sets of ranks are correlated. It could be used in a situation where one only has ranked data, such as a tally of gold, silver, and bronze medals. If a statistician wanted to know whether people who are high ranking in sprinting are also high ranking in long-distance running, they would use a Spearman rank correlation coefficient.It assesses how well the relationship between two variables can be described using a monotonic function.\n",
    "\n",
    "The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables; while Pearson's correlation assesses linear relationships, Spearman's correlation assesses monotonic relationships (whether linear or not). If there are no repeated data values, a perfect Spearman correlation of +1 or −1 occurs when each of the variables is a perfect monotone function of the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "#### b. Áp dụng tính hệ số tương quan Pearson và Spearman giữa các biến số trong bộ dữ liệu đã chọn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson = df[quantiative_columns].corr(method=\"pearson\")\n",
    "corr_spearman = df[quantiative_columns].corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "#### c. Sử dụng biểu đồ phù hợp để trực quan hóa mối quan hệ giữa các biến. (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for Pearson\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_pearson, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Pearson Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Heatmap for Spearman\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_pearson, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Spearman Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "#### d. Đưa ra nhận xét về ý nghĩa thực tiễn của các mối tương quan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "- **Tính kế thừa và dự báo mạnh mẽ (Quan trọng nhất):** Tương quan giữa Học kỳ 1 và Học kỳ 2 là rất cao (màu đỏ đậm, hệ số > 0.9). Kết quả học tập kỳ đầu là chỉ báo dự báo chính xác nhất cho kỳ sau. Sinh viên có xu hướng duy trì phong độ ổn định; ai học tốt kỳ 1 thường sẽ học tốt kỳ 2 và ngược lại. Nhà trường có thể dùng kết quả kỳ 1 để sớm phát hiện sinh viên cần hỗ trợ.\n",
    "- **Mối quan hệ giữa Nỗ lực và Kết quả:** Có sự tương quan thuận chặt chẽ giữa số môn đăng ký/tham gia đánh giá (enrolled/evaluations) và số môn đạt (approved/credited). Mức độ tích cực tham gia học tập và thi cử quyết định lớn đến kết quả đầu ra. Tuy nhiên, hệ số không phải tuyệt đối (1.0), cho thấy việc \"chăm đi thi\" là điều kiện cần nhưng chưa đủ, vẫn tồn tại tỷ lệ rớt môn nhất định.\n",
    "- **Yếu tố Kinh tế vĩ mô không tác động trực tiếp:** Các chỉ số GDP, Lạm phát, Thất nghiệp có hệ số tương quan gần bằng 0 (màu xanh nhạt/trắng) với các biến kết quả học tập.Trong phạm vi dữ liệu này, bối cảnh kinh tế bên ngoài không ảnh hưởng đáng kể đến thành tích học tập của cá nhân sinh viên. Việc học kém hay giỏi phụ thuộc vào yếu tố nội tại hơn là môi trường kinh tế vĩ mô.\n",
    "- **Tuổi tác không phải là rào cản:** Biến \"Age at enrollment\" có tương quan rất thấp với các kết quả học tập. Độ tuổi nhập học (già hay trẻ) không quyết định thành công hay thất bại trong môi trường đại học.\n",
    "\n",
    "***Tóm lại:*** Để cải thiện chất lượng đào tạo, nên tập trung giám sát kết quả ngay từ Học kỳ 1 và khuyến khích sinh viên tham gia đầy đủ các bài đánh giá, thay vì lo ngại về các yếu tố nhân khẩu học (tuổi) hay kinh tế bên ngoài."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "## 5. Hồi quy đa biến (Multiple Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày lý thuyết về Hồi quy đa biến."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "Multiple linear regression (MLR), also known simply as multiple regression, is a statistical technique that uses several explanatory variables to predict the outcome of a response variable. The goal of MLR is to model the linear relationship between the explanatory (independent) variables and response (dependent) variables. In essence, multiple regression is the extension of ordinary least-squares (OLS) regression because it involves more than one explanatory variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "Ở đây ta định nghĩa rằng biến phụ thuộc là Curricular units 2nd sem (grade) (điểm bình quân học kỳ 2 từ 0 tới 20) và các biến còn lại là biến phụ thuộc để minh họa cho hồi quy đa biến do Target của tập dữ liệu là biến định tính (nghỉ học, đang học, tốt nghiệp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "**Phát hiện đa cộng tuyến trước khi áp dụng các biến vào mô hình hồi quy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical Dataframe to apply one hot encoding\n",
    "df_categorical = df[cat_columns].copy()\n",
    "df_categorical_encoded = pd.get_dummies(df_categorical, drop_first=True, dtype=float)\n",
    "\n",
    "# Combine both categorical columns and numeric columns\n",
    "X = pd.concat([df_categorical_encoded, df_numeric], axis=1)\n",
    "\n",
    "# 1. Add a constant (Intercept)\n",
    "# This is required for the VIF calculation in statsmodels to work correctly\n",
    "X = add_constant(X)\n",
    "\n",
    "# 2. Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "\n",
    "# 3. Sort by VIF score to see the worst offenders\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN STAGING STATE BEFORE GETTING DELETED...\n",
    "\n",
    "# # 1. Define the variables you want to test\n",
    "# # (Combine your numeric predictors + the categorical ones you want to test)\n",
    "# # WARNING: 'Course' and 'Occupation' have MANY categories. \n",
    "# # Including them might create 100+ columns. Start with simpler ones like 'Marital status'.\n",
    "# cat_cols = ['Marital status', 'Application mode'] \n",
    "# num_cols = ['Age at enrollment', 'GDP', 'Curricular units 1st sem (grade)']\n",
    "\n",
    "# # 2. Select data\n",
    "# X = df[cat_cols + num_cols].copy()\n",
    "\n",
    "# # 3. CRITICAL STEP: Convert categorical numbers to Strings\n",
    "# # This tells pandas: \"Treat '1' as a name, not a number\"\n",
    "# X[cat_cols] = X[cat_cols].astype(str)\n",
    "\n",
    "# # 4. Now get_dummies will actually work\n",
    "# X_encoded = pd.get_dummies(X, drop_first=True, dtype=float)\n",
    "\n",
    "# # 5. Add Constant\n",
    "# X_encoded = add_constant(X_encoded)\n",
    "\n",
    "# # 6. Calculate VIF\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"Feature\"] = X_encoded.columns\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(X_encoded.values, i) for i in range(len(X_encoded.columns))]\n",
    "\n",
    "# print(vif_data.sort_values(by=\"VIF\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. SETUP: Define lists\n",
    "# ==========================================\n",
    "\n",
    "# The Target to EXCLUDE\n",
    "target_col = 'Curricular units 2nd sem (grade)'\n",
    "\n",
    "# List of all Categorical columns (based on dataset documentation)\n",
    "# These act like numbers but are actually categories\n",
    "cat_cols = [\n",
    "    'Marital status', 'Application mode', 'Course', \n",
    "    'Previous qualification', 'Nacionality', \n",
    "    'Mother\\'s qualification', 'Father\\'s qualification', \n",
    "    'Mother\\'s occupation', 'Father\\'s occupation',\n",
    "    'Displaced', 'Educational special needs', 'Debtor', \n",
    "    'Tuition fees up to date', 'Gender', 'Scholarship holder', \n",
    "    'International', 'Daytime/evening attendance'\n",
    "]\n",
    "\n",
    "# List of Numeric columns (excluding the target)\n",
    "num_cols = [\n",
    "    'Application order', 'Age at enrollment', \n",
    "    'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)', \n",
    "    'Curricular units 1st sem (evaluations)', 'Curricular units 1st sem (approved)', \n",
    "    'Curricular units 1st sem (grade)', 'Curricular units 1st sem (without evaluations)',\n",
    "    # Note: If predicting 2nd sem grade, usually we keep 2nd sem inputs if they are available\n",
    "    'Curricular units 2nd sem (credited)', 'Curricular units 2nd sem (enrolled)', \n",
    "    'Curricular units 2nd sem (evaluations)', 'Curricular units 2nd sem (approved)', \n",
    "    'Curricular units 2nd sem (without evaluations)',\n",
    "    'Unemployment rate', 'Inflation rate', 'GDP'\n",
    "]\n",
    "\n",
    "# Create the working dataframe\n",
    "# (Filter to ensure we only use columns that actually exist in your df)\n",
    "existing_cat = [c for c in cat_cols if c in df.columns]\n",
    "existing_num = [c for c in num_cols if c in df.columns]\n",
    "X = df[existing_cat + existing_num].copy()\n",
    "\n",
    "# ==========================================\n",
    "# 2. TOP-N STRATEGY (Handling High Cardinality)\n",
    "# ==========================================\n",
    "# For columns like 'Course' or 'Occupation', we keep the Top 10 most frequent\n",
    "# and group the rest into \"Other\" to prevent VIF explosion.\n",
    "\n",
    "TOP_N = 10 \n",
    "\n",
    "for col in existing_cat:\n",
    "    # Calculate value counts\n",
    "    top_values = X[col].value_counts().nlargest(TOP_N).index\n",
    "    \n",
    "    # Replace anything not in top_values with 'Other'\n",
    "    X[col] = X[col].apply(lambda x: x if x in top_values else 'Other')\n",
    "    \n",
    "    # Convert to string to ensure get_dummies treats it as categorical\n",
    "    X[col] = X[col].astype(str)\n",
    "\n",
    "# ==========================================\n",
    "# 3. ENCODING & VIF CALCULATION\n",
    "# ==========================================\n",
    "\n",
    "# One-Hot Encoding with drop_first=True (Crucial for VIF)\n",
    "X_encoded = pd.get_dummies(X, columns=existing_cat, drop_first=True, dtype=float)\n",
    "\n",
    "# Add Constant (Intercept)\n",
    "X_encoded = add_constant(X_encoded)\n",
    "\n",
    "# Handle potential NaNs created by processing (though this dataset usually has none)\n",
    "X_encoded = X_encoded.dropna()\n",
    "\n",
    "print(f\"Calculating VIF for {X_encoded.shape[1]} features...\")\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_encoded.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_encoded.values, i) for i in range(len(X_encoded.columns))]\n",
    "\n",
    "# ==========================================\n",
    "# 4. RESULTS\n",
    "# ==========================================\n",
    "# Sort by VIF descending\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_vif_cleaner(df_input, threshold=5.0):\n",
    "    \"\"\"\n",
    "    Iteratively drops the feature with the highest VIF until all VIFs are below the threshold.\n",
    "    \"\"\"\n",
    "    # Working copy to avoid modifying original dataframe\n",
    "    df_vif = df_input.copy()\n",
    "    \n",
    "    # Ensure constant exists\n",
    "    df_vif = add_constant(df_vif)\n",
    "    \n",
    "    # Loop until clean\n",
    "    dropped_features = []\n",
    "    iteration = 1\n",
    "    \n",
    "    while True:\n",
    "        # 1. Calculate VIF for current features\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"Feature\"] = df_vif.columns\n",
    "        vif_data[\"VIF\"] = [variance_inflation_factor(df_vif.values, i) \n",
    "                           for i in range(len(df_vif.columns))]\n",
    "        \n",
    "        # 2. Get the maximum VIF (ignoring the Constant/Intercept)\n",
    "        # We assume 'const' is in the dataframe, usually index 0\n",
    "        features_to_check = vif_data[vif_data['Feature'] != 'const']\n",
    "        \n",
    "        if features_to_check.empty:\n",
    "            print(\"No features left!\")\n",
    "            break\n",
    "            \n",
    "        max_vif = features_to_check['VIF'].max()\n",
    "        max_feature = features_to_check.sort_values('VIF', ascending=False).iloc[0]['Feature']\n",
    "        \n",
    "        # 3. Check Threshold\n",
    "        if max_vif > threshold:\n",
    "            print(f\"Iter {iteration}: Dropping '{max_feature}' (VIF={max_vif:.2f})\")\n",
    "            df_vif = df_vif.drop(columns=[max_feature])\n",
    "            dropped_features.append(max_feature)\n",
    "            iteration += 1\n",
    "        else:\n",
    "            print(f\"\\nSuccess! All remaining features have VIF < {threshold}\")\n",
    "            break\n",
    "            \n",
    "    return df_vif, dropped_features\n",
    "\n",
    "# =========================================\n",
    "# USE THE SCRIPT\n",
    "# =========================================\n",
    "\n",
    "# 1. Prepare your X (encoded) matrix same as before\n",
    "# (Make sure to exclude your Target variable first!)\n",
    "# Assuming X_encoded is your dataframe from the previous step\n",
    "# If you need to recreate it:\n",
    "# X_encoded = pd.get_dummies(X, columns=cat_cols_clean, drop_first=True, dtype=float)\n",
    "\n",
    "# 2. Run the Cleaner\n",
    "X_clean, dropped_list = dynamic_vif_cleaner(X_encoded, threshold=5.0)\n",
    "\n",
    "# 3. Show Final VIFs\n",
    "final_vif = pd.DataFrame()\n",
    "final_vif[\"Feature\"] = X_clean.columns\n",
    "final_vif[\"VIF\"] = [variance_inflation_factor(X_clean.values, i) for i in range(len(X_clean.columns))]\n",
    "print(\"\\nFinal VIF Table:\")\n",
    "print(final_vif.sort_values(by=\"VIF\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "### b. Xây dựng và đánh giá mô hình hồi quy tuyến tính đa biến nhằm dự đoán một biến phụ thuộc (biến mục tiêu) dựa trên nhiều biến độc lập trong bộ dữ liệu đã chọn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CELL IS IN STAGING STATE AND WAITING TO BE REMOVED...\n",
    "\n",
    "# Predict 'Curricular units 2nd sem (grade)' based on other factors\n",
    "target_col = \"Curricular units 2nd sem (grade)\"\n",
    "features = [\n",
    "    # \"Age at enrollment\",\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    # \"GDP\",\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target_col]\n",
    "\n",
    "# Add constant\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit model\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Save summary to file\n",
    "with open(\"regression_summary.txt\", \"w\") as f:\n",
    "    f.write(model.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remerge the target variable to the clean X rows (if indices align)\n",
    "# y = df['Curricular units 2nd sem (grade)']\n",
    "\n",
    "model = sm.OLS(y, X_clean).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Goldilocks\" Model\n",
    "# Keep the strong predictors from B, add the best signals from A\n",
    "X_hybrid = df[[\n",
    "    'Curricular units 1st sem (grade)', \n",
    "    # 'Age at enrollment', \n",
    "    'GDP', \n",
    "    'Tuition fees up to date',\n",
    "    'Scholarship holder'\n",
    "]].copy()\n",
    "\n",
    "# Add Course dummies (since Course was very strong in Model A)\n",
    "# Use your \"Top-N\" logic here for Course\n",
    "top_courses = df['Course'].value_counts().nlargest(5).index\n",
    "X_hybrid['Course_Group'] = df['Course'].apply(lambda x: str(x) if x in top_courses else 'Other')\n",
    "X_hybrid = pd.get_dummies(X_hybrid, columns=['Course_Group'], drop_first=True, dtype=float)\n",
    "\n",
    "# Run OLS\n",
    "X_hybrid = sm.add_constant(X_hybrid)\n",
    "model = sm.OLS(y, X_hybrid).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final VIF Check on the \"Hybrid\" Model\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming 'X_hybrid' is the dataframe used in your final model\n",
    "# Make sure constant is added\n",
    "X_check = sm.add_constant(X_hybrid)\n",
    "\n",
    "vif_final = pd.DataFrame()\n",
    "vif_final[\"Feature\"] = X_check.columns\n",
    "vif_final[\"VIF\"] = [variance_inflation_factor(X_check.values, i) for i in range(len(X_check.columns))]\n",
    "\n",
    "print(vif_final.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================================\n",
    "# 1. FEATURE ENGINEERING (The Final Selection)\n",
    "# ==========================================\n",
    "# Create a fresh copy of the data\n",
    "X_final = df[[\n",
    "    'Curricular units 1st sem (grade)', \n",
    "    'Age at enrollment', \n",
    "    'GDP', \n",
    "    'Tuition fees up to date',\n",
    "    'Scholarship holder'\n",
    "]].copy()\n",
    "\n",
    "# Create ONLY the one significant Course Dummy (Nursing/Health Services)\n",
    "# We ignore the others because their P-values were > 0.05\n",
    "X_final['Course_Is_Nursing'] = (df['Course'] == 9500).astype(int)\n",
    "\n",
    "# Add Constant\n",
    "X_final = sm.add_constant(X_final)\n",
    "\n",
    "# ==========================================\n",
    "# 2. RUN THE FINAL MODEL\n",
    "# ==========================================\n",
    "y = df['Curricular units 2nd sem (grade)']\n",
    "model_final = sm.OLS(y, X_final).fit()\n",
    "\n",
    "# Print Summary for your records\n",
    "print(model_final.summary())\n",
    "\n",
    "# ==========================================\n",
    "# 3. GENERATE EXECUTIVE SUMMARY PLOT\n",
    "# ==========================================\n",
    "# Extract coefficients and confidence intervals\n",
    "results_df = pd.DataFrame({\n",
    "    'Feature': model_final.params.index,\n",
    "    'Coef': model_final.params.values,\n",
    "    'Error': model_final.bse.values\n",
    "})\n",
    "\n",
    "# Remove 'const' (Intercept) from the plot as it's not an \"driver\"\n",
    "results_df = results_df[results_df['Feature'] != 'const']\n",
    "\n",
    "# Sort by magnitude of impact\n",
    "results_df = results_df.sort_values(by='Coef', ascending=False)\n",
    "\n",
    "# Create the Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot = sns.barplot(x='Coef', y='Feature', data=results_df, palette='viridis')\n",
    "\n",
    "# Add error bars to show statistical significance\n",
    "plt.errorbar(x=results_df['Coef'], y=results_df.index, \n",
    "             xerr=1.96 * results_df['Error'], fmt='none', c='black', capsize=5)\n",
    "\n",
    "# Add a vertical line at 0 (No Impact zone)\n",
    "plt.axvline(x=0, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "# Formatting\n",
    "plt.title('Predictors of 2nd Semester Grades (Executive Summary)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Impact on Grade (Points)', fontsize=12)\n",
    "plt.ylabel('')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Annotate the bars with the actual values\n",
    "for i, v in enumerate(results_df['Coef']):\n",
    "    plot.text(v + (0.02 if v > 0 else -0.02), i, f'{v:.2f}', \n",
    "              va='center', fontweight='bold', \n",
    "              ha='left' if v > 0 else 'right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
