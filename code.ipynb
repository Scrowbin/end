{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Nhập thư viện và đọc dữ liệu từ file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import dython\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "df = pd.read_csv(\"data.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Khám phá dữ liệu (Exploratory Data Analysis - EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### a. Tóm tắt thông tin dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "cái df này nó chỉ có cột target là cat thôi vì trên uci nó đã label encode r lọc ra thành mấy cột integer r nên h đi tìm lại để tìm tương quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=[\"object\"])\n",
    "print(cat_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['number'])\n",
    "print(num_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_like = [col for col in df.columns if df[col].nunique() < 50]\n",
    "print(cat_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiative_columns = [\n",
    "    'Age at enrollment',\n",
    "    'Curricular units 1st sem (credited)',\n",
    "    'Curricular units 1st sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)',\n",
    "    'Curricular units 1st sem (approved)',\n",
    "    'Curricular units 1st sem (without evaluations)',\n",
    "    'Curricular units 2nd sem (credited)',\n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 2nd sem (evaluations)',\n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 2nd sem (without evaluations)',\n",
    "    'Unemployment rate',\n",
    "    'Inflation rate',\n",
    "    'GDP'\n",
    "]\n",
    "\n",
    "cat_columns = [col for col in cat_like if col not in quantiative_columns]\n",
    "ordinal_column = [\"Application order\"]\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Kiểm tra số lượng bản ghi, số lượng biến số, kiểu dữ liệu của từng biến.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Xử lý dữ liệu thiếu, dữ liệu trùng lặp (nếu có).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### b. Phân tích thống kê mô tả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Tính các thống kê như trung bình, trung vị, độ lệch chuẩn, tứ phân vị.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.drop(columns=cat_columns)\n",
    "df_numeric.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Histogram split by target\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x='Admission grade',\n",
    "    hue='Target',        # separates Dropout vs Graduate\n",
    "    bins=20,             # adjust for clarity\n",
    "    kde=True,            # optional: overlay density\n",
    "    stat='density',      # normalize for comparison\n",
    "    palette=['red', 'green','blue'],\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "plt.title('Admission grade distribution by Target')\n",
    "plt.xlabel('Admission grade')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Trực quan hoá bằng các biểu đồ phù hợp (ít nhất 3 loại biểu đồ) để nhận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a countplot:\n",
    "# x-axis: The outcome (Target)\n",
    "# hue: The secondary variable used to group the bars (Attendance Status)\n",
    "# palette: Uses the same color scheme as the previous example (reds/greens) for consistency\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x='Target',\n",
    "    hue='Daytime/evening attendance\\t',\n",
    "    palette={'green','red'},\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# --- 3. CUSTOMIZE PLOT AESTHETICS ---\n",
    "plt.title('Student Outcome (Target) by Attendance Status', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Student Outcome', fontsize=14)\n",
    "plt.ylabel('Count of Students', fontsize=14)\n",
    "plt.legend(title='Attendance Status', title_fontsize='12', fontsize='10')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "attendance_col = 'Daytime/evening attendance\\t'  # keep the tab if it's in the column name\n",
    "target_col = 'Target'\n",
    "\n",
    "# Count occurrences\n",
    "counts = df.groupby([attendance_col, target_col]).size().reset_index(name='count')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=counts, x=attendance_col, y='count', hue=target_col)\n",
    "plt.xlabel('Attendance Type (0=Daytime, 1=Evening)')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.title('Attendance Type vs Final Target')\n",
    "plt.legend(title='Target')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "this data makes sense specially for this dataset since this is A dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies. \n",
    "\n",
    "i.e. they have jobs in the day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_col = 'Daytime/evening attendance\\t'\n",
    "target_col = 'Target'\n",
    "\n",
    "categories = ['Dropout', 'Enrolled', 'Graduate']\n",
    "\n",
    "daytime_counts = df[df[attendance_col] == 0][target_col].value_counts().reindex(categories)\n",
    "evening_counts = df[df[attendance_col] == 1][target_col].value_counts().reindex(categories)\n",
    "\n",
    "# Create two side-by-side pie charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "axes[0].pie(daytime_counts, labels=daytime_counts.index, autopct='%1.1f%%', startangle=90, colors=[\"#ff0000\",'#8da0cb','#66c2a5'])\n",
    "axes[0].set_title('Daytime Attendance')\n",
    "\n",
    "axes[1].pie(evening_counts, labels=evening_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff0000','#8da0cb','#66c2a5'])\n",
    "axes[1].set_title('Evening Attendance')\n",
    "\n",
    "plt.suptitle('Target Distribution by Attendance Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "this one shows percantage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Same thing but for scholarship (this should be obvious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_col = 'Scholarship holder'  # keep the tab if it's in the column name\n",
    "target_col = 'Target'\n",
    "\n",
    "# Count occurrences\n",
    "counts = df.groupby([var_col, target_col]).size().reset_index(name='count')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=counts, x=var_col, y='count', hue=target_col)\n",
    "plt.xlabel('Scholarship holder (0=No, 1=Yes)')\n",
    "plt.ylabel('Number of Students')\n",
    "plt.title('Scholarship Type vs Final Target')\n",
    "plt.legend(title='Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_col = 'Scholarship holder'  \n",
    "target_col = 'Target'\n",
    "\n",
    "categories = ['Dropout', 'Enrolled', 'Graduate']\n",
    "\n",
    "no = df[df[var_col] == 0][target_col].value_counts().reindex(categories)\n",
    "yes = df[df[var_col] == 1][target_col].value_counts().reindex(categories)\n",
    "\n",
    "# Create two side-by-side pie charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "\n",
    "axes[0].pie(no, labels=no.index, autopct='%1.1f%%', startangle=90, colors=[\"#ff0000\",'#8da0cb','#66c2a5'])\n",
    "axes[0].set_title('Non scholarship holders')\n",
    "\n",
    "axes[1].pie(yes, labels=yes.index, autopct='%1.1f%%', startangle=90, colors=['#ff0000','#8da0cb','#66c2a5'])\n",
    "axes[1].set_title('Scholarship holders')\n",
    "\n",
    "plt.suptitle('Target Distribution by Scholarship Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### c. Phát hiện dữ liệu ngoại lai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Sử dụng IQR (Interquartile Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "df_numeric.boxplot(rot=90)  # rot=90 to rotate x-axis labels\n",
    "plt.title(\"Boxplots of All Numeric Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "**investigating gdp, inflation and unemployment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['GDP', 'Unemployment rate', 'Inflation rate']]\n",
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Knowing that the data comes from the Instituto Politécnico de Portalegre (IPP) in Portugal directly confirms two key points that validate our previous investigation:\n",
    "\n",
    "Country: The economic data is relevant to Portugal.\n",
    "\n",
    "Context: The data is from a Portuguese polytechnic institute during a specific time period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "| Metric            | Range (Min to Max) | Confirmed Context                                                                 | Conclusion                                           |\n",
    "|------------------|-------------------|----------------------------------------------------------------------------------|----------------------------------------------------|\n",
    "| Unemployment Rate | 7.6% to 16.2%     | Matches the severe economic crisis and subsequent recovery in Portugal (roughly 2008–2018). | Plausible. The highest values are likely accurate historical peaks. |\n",
    "| Inflation Rate    | -0.8% to 3.7%     | Matches Portugal's largely stable, low-inflation environment during that period, including some deflationary dips. | Plausible. Very stable and reliable data.         |\n",
    "| GDP               | -4.06 to 3.51     | Matches Portugal's sharp recessionary decline followed by years of recovery growth. | Plausible. Represents real economic volatility.   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "phương pháp xử lý đề xuất (cho mấy cột trên với lại mấy cái course)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "***!!!Square Root Transformation!!!***\n",
    "might or might or have to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "You only transform the distribution (log/square root) for features that are highly skewed (like GDP and Curricular Units). You must apply scaling to every continuous numeric column to ensure no single variable dominates your model due to its large value range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "***NHẬN XÉT TỔNG QUAN SO FAR***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## 2. Phân tích phân phối xác suất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### Chọn ít nhất hai biến số quan trọng và kiểm tra xem nó có tuân theo phân phối xác suất nào không (chuẩn, Poisson, exponential…) sử dụng biểu đồ phù hợp để minh hoạ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Application order\"\n",
    "data = df[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Admission grade\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Age at enrollment\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Curricular units 1st sem (grade)\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Curricular units 2nd sem (grade)\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)     # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color='skyblue', stat='density')\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'r', linewidth=2)\n",
    "\n",
    "plt.title(f'{col} (mu={mu:.2f}, std={std:.2f})')\n",
    "plt.xlabel(col)\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## 3. Kiểm định giả thuyết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày các kiểm định thống kê sau: t-test, Chi-square và ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### b. Đề xuất hai câu hỏi nghiên cứu có thể kiểm định bằng dữ liệu cho bộ dữ liệu đã chọn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "câu hỏi: giới tính khác nhau có ảnh hưởng đến cái dropout rate hay ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Tạo bảng tần số (contingency table)\n",
    "table = pd.crosstab(df['Gender'], df['Target'])\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, expected = chi2_contingency(table)\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Expected frequencies:\\n\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): Giới tính và kết quả học tập không liên quan (độc lập)\n",
    "\n",
    "Alternative hypothesis (H1): Có sự phụ thuộc giữa giới tính và kết quả học tập\n",
    "\n",
    "Nếu p < 0.05 → bác bỏ H0 → có sự khác biệt có ý nghĩa\n",
    "\n",
    "Nếu p >= 0.05 → không bác bỏ H0 → không có bằng chứng về sự khác biệt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Vì p << 0.05, chúng ta bác bỏ H0 → kết luận:\n",
    "\n",
    "Có sự khác biệt rất rõ ràng về kết quả học tập giữa nam và nữ. Giới tính và Target không độc lập trong dữ liệu này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_norm = table.div(table.sum(axis=1), axis=0)  # chuyển sang tỉ lệ %\n",
    "table_norm.plot(kind='bar', stacked=True, figsize=(8,5), colormap='Set2')\n",
    "\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xlabel(\"Gender (0=Male, 1=Female)\")\n",
    "plt.title(\"Target distribution by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Bảng tỉ lệ %\n",
    "table_percent = table.div(table.sum(axis=1), axis=0) * 100\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(table_percent, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Gender (0=Male, 1=Female)\")\n",
    "plt.title(\"Heatmap of Target distribution by Gender (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data=df, x='Admission grade', hue='Gender', \n",
    "             bins=20, kde=True, palette=['blue','orange'], alpha=0.6, stat='density')\n",
    "\n",
    "plt.title('Distribution of Admission Grade by Gender')\n",
    "plt.xlabel('Admission Grade')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(title='Gender', labels=['Female','Male'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "wowza! kết quả cho thấy có sự chênh lệch rõ ràng giữa hai giới tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "#### Kiểm định khác biệt độ tuồi giữa các nhóm target bằng anova ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "anova cần mấy biến tuân theo phân phối chuẩn, nên t đi check coi chuẩn ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "from scipy.stats import levene\n",
    "\n",
    "groups = df.groupby('Target')['Age at enrollment']\n",
    "\n",
    "for name, group_data in groups:\n",
    "    stat, p = shapiro(group_data.dropna())  # drop NA values\n",
    "    print(f\"{name}: W={stat:.3f}, p={p:.3f}\")\n",
    "\n",
    "groups = [group.dropna() for name, group in df.groupby('Target')['Age at enrollment']]\n",
    "\n",
    "stat, p = levene(*groups)\n",
    "print(f\"Levene’s test: W={stat:.3f}, p={p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "⚠️ This violates the normality assumption for ANOVA.\n",
    "\n",
    "⚠️ This violates the homogeneity of variance assumption for ANOVA.\n",
    "\n",
    "Since both normality and equal variance assumptions are violated, one-way ANOVA is NOT appropriate here.\n",
    "\n",
    "✅ Correct approach:\n",
    "Use a non-parametric alternative like Kruskal-Wallis test, which does not assume normality or equal variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "dropout_age = df[df['Target']=='Dropout']['Age at enrollment']\n",
    "enrolled_age = df[df['Target']=='Enrolled']['Age at enrollment']\n",
    "graduate_age = df[df['Target']=='Graduate']['Age at enrollment']\n",
    "\n",
    "stat, p = kruskal(dropout_age, enrolled_age, graduate_age)\n",
    "print(f\"Kruskal-Wallis test: H={stat:.3f}, p={p:.3e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "Since p << 0.05, you reject the null hypothesis. This means there is a statistically significant difference between at least one pair of your groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "Minh họa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for plotting\n",
    "plot_df = df[['Target', 'Age at enrollment']].dropna()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.violinplot(x='Target', y='Age at enrollment', data=plot_df, palette=\"Set3\")\n",
    "plt.title(\"Age at Enrollment by Target Group\")\n",
    "plt.ylabel(\"Age at Enrollment\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "Kết luận: Dữ liệu cho thấy mối quan hệ nghịch đảo giữa độ tuổi nhập học và khả năng tốt nghiệp. Về mặt thống kê, những sinh viên nhập học ở độ tuổi truyền thống sớm hơn có khả năng hoàn thành chương trình học cao hơn nhiều so với những sinh viên nhập học muộn hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "## 4. Phân tích tương quan giữa các biến"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày hệ số tương quan Pearson và Spearman."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "Pearson correlation coefficient (PCC) is a correlation coefficient that measures linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations; thus, it is essentially a normalized measurement of the covariance, such that the result always has a value between −1 and 1. As a simple example, one would expect the age and height of a sample of children from a school to have a Pearson correlation coefficient significantly greater than 0, but less than 1 (as 1 would represent an unrealistically perfect correlation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "Spearman's rank correlation coefficient or Spearman's ρ is a number ranging from -1 to 1 that indicates how strongly two sets of ranks are correlated. It could be used in a situation where one only has ranked data, such as a tally of gold, silver, and bronze medals. If a statistician wanted to know whether people who are high ranking in sprinting are also high ranking in long-distance running, they would use a Spearman rank correlation coefficient.It assesses how well the relationship between two variables can be described using a monotonic function.\n",
    "\n",
    "The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables; while Pearson's correlation assesses linear relationships, Spearman's correlation assesses monotonic relationships (whether linear or not). If there are no repeated data values, a perfect Spearman correlation of +1 or −1 occurs when each of the variables is a perfect monotone function of the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "#### b. Áp dụng tính hệ số tương quan Pearson và Spearman giữa các biến số trong bộ dữ liệu đã chọn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson = df[quantiative_columns].corr(method=\"pearson\")\n",
    "corr_spearman = df[quantiative_columns].corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "#### c. Sử dụng biểu đồ phù hợp để trực quan hóa mối quan hệ giữa các biến. (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for Pearson\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_pearson, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Pearson Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Heatmap for Spearman\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_pearson, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Spearman Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "#### d. Đưa ra nhận xét về ý nghĩa thực tiễn của các mối tương quan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "- **Tính kế thừa và dự báo mạnh mẽ (Quan trọng nhất):** Tương quan giữa Học kỳ 1 và Học kỳ 2 là rất cao (màu đỏ đậm, hệ số > 0.9). Kết quả học tập kỳ đầu là chỉ báo dự báo chính xác nhất cho kỳ sau. Sinh viên có xu hướng duy trì phong độ ổn định; ai học tốt kỳ 1 thường sẽ học tốt kỳ 2 và ngược lại. Nhà trường có thể dùng kết quả kỳ 1 để sớm phát hiện sinh viên cần hỗ trợ.\n",
    "- **Mối quan hệ giữa Nỗ lực và Kết quả:** Có sự tương quan thuận chặt chẽ giữa số môn đăng ký/tham gia đánh giá (enrolled/evaluations) và số môn đạt (approved/credited). Mức độ tích cực tham gia học tập và thi cử quyết định lớn đến kết quả đầu ra. Tuy nhiên, hệ số không phải tuyệt đối (1.0), cho thấy việc \"chăm đi thi\" là điều kiện cần nhưng chưa đủ, vẫn tồn tại tỷ lệ rớt môn nhất định.\n",
    "- **Yếu tố Kinh tế vĩ mô không tác động trực tiếp:** Các chỉ số GDP, Lạm phát, Thất nghiệp có hệ số tương quan gần bằng 0 (màu xanh nhạt/trắng) với các biến kết quả học tập.Trong phạm vi dữ liệu này, bối cảnh kinh tế bên ngoài không ảnh hưởng đáng kể đến thành tích học tập của cá nhân sinh viên. Việc học kém hay giỏi phụ thuộc vào yếu tố nội tại hơn là môi trường kinh tế vĩ mô.\n",
    "- **Tuổi tác không phải là rào cản:** Biến \"Age at enrollment\" có tương quan rất thấp với các kết quả học tập. Độ tuổi nhập học (già hay trẻ) không quyết định thành công hay thất bại trong môi trường đại học.\n",
    "\n",
    "***Tóm lại:*** Để cải thiện chất lượng đào tạo, nên tập trung giám sát kết quả ngay từ Học kỳ 1 và khuyến khích sinh viên tham gia đầy đủ các bài đánh giá, thay vì lo ngại về các yếu tố nhân khẩu học (tuổi) hay kinh tế bên ngoài."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "## 5. Hồi quy đa biến (Multiple Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày lý thuyết về Hồi quy đa biến."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "Hồi quy đa biến là một kĩ thuật thống kê sử dụng nhiều biến độc lập (các thuộc tính) để dự đoán kết quả của một biến phụ thuốc, các biến độc lập này lý tưởng sẽ có ý nghĩa để giải thích sẽ mô hình huấn luyện này. Mục đích của hồi quy đa biến là mô hình hóa mối tương quan tuyến tính giữa các biến độc lập với biến phụ thuộc. Về cơ bản, hồi quy đa biến là một hồi quy tuyến tính vì nó bao gồm nhiều hơn một biến độc lập."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "### b. Xây dựng và đánh giá mô hình hồi quy tuyến tính đa biến nhằm dự đoán một biến phụ thuộc (biến mục tiêu) dựa trên nhiều biến độc lập trong bộ dữ liệu đã chọn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "Ở đây ta định nghĩa rằng biến phụ thuộc là Curricular units 2nd sem (grade) (điểm bình quân học kỳ 2 từ 0 tới 20) và các biến còn lại là biến phụ thuộc để minh họa cho hồi quy đa biến do Target của tập dữ liệu là biến định tính (nghỉ học, đang học, tốt nghiệp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "Chúng tôi đã chủ động tránh việc áp dụng One-Hot Encoding toàn phần cho các đặc trưng có tính đa dạng cao (high-cardinality) – như Nghề nghiệp và Khóa học – để ngăn chặn 'Lời nguyền của số chiều' (The Curse of Dimensionality).\n",
    "\n",
    "Rất nhiều giá trị phân loại trong số này có độ hỗ trợ (Support) thấp (chiếm dưới 1% tập dữ liệu), tạo ra các 'Đặc trưng thưa' (Sparse Features) dẫn đến việc mô hình mất ổn định và bị quá khớp (overfitting).\n",
    "\n",
    "Thay vào đó, chúng tôi ưu tiên các đặc trưng có độ hỗ trợ cao, bao quát được toàn bộ tổng thể. Điều này đảm bảo mô hình sẽ học được các quy luật hành vi tổng quát thay vì chỉ 'học vẹt' (ghi nhớ) các nhóm nhỏ lẻ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "Support là tỉ lệ giữa độ tần suất của một biến với cả tập dữ liệu. Nó được sử dụng để tìm một tập các biến xuất hiện có thường xuyên hay không trong tập dữ liệu. Công thức:\n",
    "$$ \\text{Support}(X) = \\frac{\\text{Number of transactions containing itemset X}}{\\text{Total number of transactions}} $$\n",
    "Sau đây chúng tôi sẽ thử nghiệm và áp dụng công thức này lên tất cả các cột trong tập dữ liệu để xét xem thử mức độ thưa thớt của các cột trên tập dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Continuous Columns\n",
    "continuous_cols = [\n",
    "    'Curricular units 1st sem (grade)', \n",
    "    'Curricular units 2nd sem (grade)',\n",
    "    'Curricular units 1st sem (enrolled)', \n",
    "    'Curricular units 2nd sem (enrolled)',\n",
    "    'Curricular units 1st sem (evaluations)', \n",
    "    'Curricular units 2nd sem (evaluations)',\n",
    "    'Curricular units 1st sem (approved)', \n",
    "    'Curricular units 2nd sem (approved)',\n",
    "    'Curricular units 1st sem (credited)', \n",
    "    'Curricular units 2nd sem (credited)',\n",
    "    'Curricular units 1st sem (without evaluations)', \n",
    "    'Curricular units 2nd sem (without evaluations)',\n",
    "    'Age at enrollment', \n",
    "    'Unemployment rate', \n",
    "    'Inflation rate', \n",
    "    'GDP',\n",
    "    'Application order',\n",
    "    'Previous qualification (grade)',\n",
    "    'Admission grade'\n",
    "]\n",
    "\n",
    "# 2. Dynamically identify ALL other columns (The \"Hidden\" Categories)\n",
    "df.columns = df.columns.str.strip() \n",
    "categorical_candidates = [col for col in df.columns if col not in continuous_cols]\n",
    "\n",
    "# 3. Run the Audit\n",
    "audit_data = []\n",
    "\n",
    "for col in categorical_candidates:\n",
    "    # Get the distribution percentages\n",
    "    counts = df[col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    total_categories = len(counts)\n",
    "    rare_categories = len(counts[counts < 1.0]) \n",
    "    \n",
    "    if total_categories > 0:\n",
    "        sparsity_rate = (rare_categories / total_categories) * 100 # Support value\n",
    "    else:\n",
    "        sparsity_rate = 0\n",
    "    \n",
    "    audit_data.append({\n",
    "        'Feature': col,\n",
    "        'Total Cats': total_categories,\n",
    "        'Rare Cats (<1%)': rare_categories,\n",
    "        'Sparsity Rate (%)': round(sparsity_rate, 1)\n",
    "    })\n",
    "\n",
    "# 4. Sort and Display\n",
    "audit_df = pd.DataFrame(audit_data).sort_values(by='Sparsity Rate (%)', ascending=False)\n",
    "\n",
    "# FIX: Explicitly remove any lingering tabs in the Feature column before plotting\n",
    "audit_df['Feature'] = audit_df['Feature'].astype(str).str.replace('\\t', '', regex=False)\n",
    "\n",
    "print(f\"--- FULL DATASET AUDIT ({len(categorical_candidates)} Columns Scanned) ---\")\n",
    "print(audit_df)\n",
    "\n",
    "# 5. Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.barplot(\n",
    "    x='Sparsity Rate (%)', \n",
    "    y='Feature', \n",
    "    data=audit_df, \n",
    "    palette='magma', \n",
    "    hue='Feature', \n",
    "    legend=False\n",
    ")\n",
    "\n",
    "plt.title('Sparsity Audit: Which columns are mostly \"Junk\"?', fontsize=14, fontweight='bold')\n",
    "\n",
    "# FIX: Removed plt.legend() because it was empty and causing a warning\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "- **Lý do ưu tiên các Đặc trưng có \"Độ thưa thấp\" (0%)**\n",
    "    - Quá trình kiểm tra cho thấy các đặc trưng có số lượng phân loại lớn (high-cardinality) như Nationality (Quốc tịch) và Occupation (Nghề nghiệp) bị thưa thớt nghiêm trọng, trong đó hơn 80% các danh mục xuất hiện trong dưới 1% tập dữ liệu. Việc đưa các đặc trưng này vào sẽ tạo ra hai vấn đề nghiêm trọng:\n",
    "    - Quá khớp (Overfitting): Mô hình sẽ \"ghi nhớ\" các danh mục hiếm (ví dụ: một công việc cụ thể chỉ có 3 sinh viên làm) thay vì học các mẫu tổng quát hóa.\n",
    "    - Không ổn định (Instability): Các hệ số được suy ra từ các mẫu có kích thước quá nhỏ sẽ không đáng tin cậy về mặt thống kê.\n",
    "\n",
    "Vì tập dữ liệu này đã lớn sẵn và khi được phân rã các biến định tính bằng one hot encoding sẽ làm cho tập dữ liệu càng rối thêm. Để làm cho mô hình đơn giản, dễ hiểu và không quá dài dòng thì chúng tôi giới hạn danh sách ứng viên vào các đặc trưng có độ thưa 0% (Độ hỗ trợ cao/High Support), chúng tôi đảm bảo rằng mọi biến đều áp dụng cho một phần lớn của tập hợp sinh viên. Điều này đảm bảo mô hình học được các mẫu hành vi toàn cục thay vì nhiễu cục bộ.\n",
    "\n",
    "- **Loại trừ Biến \"Target\" (Rò rỉ dữ liệu)**: Mặc dù biến Target (Tốt nghiệp/Bỏ học) xuất hiện trong danh sách Độ thưa 0%, nó bị loại trừ khỏi danh sách ứng viên do vấn đề Rò rỉ dữ liệu (Data Leakage). Target đại diện cho kết quả cuối cùng của văn bằng (thông tin tương lai). Trong kịch bản dự đoán thực tế (ví dụ: dự đoán điểm số khi bắt đầu Học kỳ 2), chúng ta không thể biết liệu sinh viên đó có tốt nghiệp nhiều năm sau hay không. Việc sử dụng Target để dự đoán Điểm học kỳ 2 sẽ thổi phồng độ chính xác một cách nhân tạo bằng thông tin không có sẵn tại thời điểm dự đoán.\n",
    "\n",
    "- **Về GDP**: Chúng tôi giữ lại GDP (và các chỉ số kinh tế liên quan) làm ứng viên. Khác với Target, các giá trị này thường được ghi nhận tại thời điểm nhập học hoặc là các trung bình kinh tế vĩ mô hàng năm đã biết trong suốt học kỳ. Chúng cung cấp bối cảnh môi trường hợp lệ mà không vi phạm logic thời gian.\n",
    "\n",
    "- **Danh sách Ứng viên Sơ bộ (Trước khi Kiểm định Thống kê)**: Dựa trên tiêu chí Độ thưa 0%, chúng tôi giữ lại toàn bộ danh sách các biến an toàn (High Support) dưới đây để tiến hành các bước kiểm định tiếp theo:\n",
    "    - Nhóm Tài chính: Tuition fees up to date, Debtor, Scholarship holder.\n",
    "    - Nhóm Nhân khẩu học: Age at enrollment, Gender, Displaced, International.\n",
    "    - Nhóm Hành vi/Khác: Daytime/evening attendance, Educational special needs.\n",
    "    - Nhóm Kinh tế/Học thuật: GDP, Curricular units 1st sem (grade).\n",
    "\n",
    "- **Kế hoạch Kiểm định Thống kê (Validation Plan)**: Để gạn lọc danh sách sơ bộ này, chúng tôi sẽ áp dụng hai bước kiểm tra thống kê cho tất cả các ứng viên trong danh sách trên:\n",
    "    - Bước 1: Kiểm tra VIF để Phát hiện các biến bị dư thừa (Multicollinearity). Chúng tôi sẽ kiểm tra ván đề đa cộng tuyến của các ứng cử viên này và loại bỏ (nếu có) các thuộc với giá trị VIF cao (lớn hơn 5).\n",
    "    - Bước 2: Chạy mô hình OLS với tất cả ứng viên còn lại. Nếu một biến có P-value > 0.05, nó chứng tỏ biến đó không đóng góp thông tin giá trị khi đã có các biến khác, và sẽ bị loại bỏ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "Phát hiện đa cộng tuyến trước khi áp dụng các biến vào mô hình hồi quy và loại bỏ các ứng cử viên được xem là không quan trọng về mặt thống kê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# We will check vif to avoid multicolinearity\n",
    "# 1. Define list of 0% sparsity features\n",
    "redundancy_columns_check = [\n",
    "    'Daytime/evening attendance',\n",
    "    'Displaced',\n",
    "    'Educational special needs',\n",
    "    'Debtor', \n",
    "    'Tuition fees up to date',\n",
    "    'Gender',\n",
    "    'Scholarship holder',\n",
    "    'International',\n",
    "    'Age at enrollment',\n",
    "]\n",
    "\n",
    "redundancy_df_check = df[redundancy_columns_check]\n",
    "# 2. Add a constant (intercept) for the VIF calculation\n",
    "# (statsmodels OLS requires an intercept to calculate VIF correctly)\n",
    "X_vif = redundancy_df_check.assign(const=1)\n",
    "\n",
    "# 3. Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_vif.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) \n",
    "                   for i in range(len(X_vif.columns))]\n",
    "\n",
    "# 4. Sort and Display\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "Kết quả cho thấy tất cả thuộc tính đều có giá trị vif rất thấp nên tạm thời có thể đưa vô mô hình ols một cách an toàn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# We create a model with all these candidates\n",
    "X_challenger = sm.add_constant(redundancy_df_check)\n",
    "y = df['Curricular units 2nd sem (grade)']\n",
    "\n",
    "model_challenger = sm.OLS(y, X_challenger).fit()\n",
    "\n",
    "print(\"--- EVIDENCE B: The 'Challenger' Model Results ---\")\n",
    "print(model_challenger.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "Chúng tôi sẽ tập trung vào cột P|t|, nếu giá trị hơn 0.05 thì biến sẽ không đáng kể về mặt thống kê và sẽ được loại bỏ ra khỏi mô hình hồi quy đa biến OLS.\n",
    "\n",
    "Candidates for Removal (The \"Cleanup List\"):\n",
    "\n",
    "Daytime/evening attendance (0.446) → Drop.\n",
    "\n",
    "International (0.384) → Drop.\n",
    "\n",
    "Displaced (0.361) → Drop.\n",
    "\n",
    "Debtor (0.277) → Drop.\n",
    "\n",
    "Educational special needs (0.087) → Drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "Sau đó chúng tôi sẽ huấn luyện lại mô hình với các biến có ý nghĩa thống kê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Evidence-Based Feature List\n",
    "# - Low Sparsity (Stable)\n",
    "# - No Leakage (Realistic)\n",
    "# - Statistically Significant (Useful)\n",
    "features = [\n",
    "    'Curricular units 1st sem (grade)',  # Academic Momentum\n",
    "    'Tuition fees up to date',           # Financial Commitment\n",
    "    'Scholarship holder',                # Financial Incentive\n",
    "    'Age at enrollment',                 # Demographic Risk\n",
    "    'GDP',                               # Economic Context (At Enrollment)\n",
    "    'Gender',                            # Demographic Baseline\n",
    "]\n",
    "\n",
    "# 2. Prepare Data\n",
    "X_final = df[features].copy()\n",
    "X_final = sm.add_constant(X_final)\n",
    "y = df['Curricular units 2nd sem (grade)']\n",
    "\n",
    "# 3. Run OLS\n",
    "model_final = sm.OLS(y, X_final).fit()\n",
    "\n",
    "# 4. Show the World\n",
    "print(model_final.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "- **Độ phù hợp của mô hình (Model Fit)**: Hệ số xác định R2=0.712 cho thấy mô hình giải thích được 71.2% sự biến thiên của biến phụ thuộc (Điểm môn học kỳ 2). Đây là mức cao đối với dữ liệu xã hội/giáo dục. Chỉ số Prob (F-statistic) xác nhận mô hình tổng thể là tin cậy, các biến độc lập thực sự có tác động đến biến phụ thuộc.\n",
    "\n",
    "- **Đánh giá các biến độc lập (Coefficients)**: Tất cả 6 biến đưa vào mô hình đều có ý nghĩa thống kê (P>∣t∣ đều nhỏ hơn 0.05). \n",
    "    - Các biến có tác động tích cực (Làm tăng điểm):\n",
    "        - Điểm kỳ 1 (Curricular units 1st sem): Là biến quan trọng nhất (t-stat cao nhất). Cứ tăng 1 điểm kỳ 1 thì điểm kỳ 2 tăng trung bình 0.86 điểm. \n",
    "        - Đóng học phí (Tuition fees up to date), sinh viên đóng học phí đúng hạn có điểm cao hơn đáng kể (hệ số 1.37).\n",
    "        - Học bổng & GDP: Có tác động dương nhưng mức độ nhẹ hơn.\n",
    "    - Các biến tác động tiêu cực (Làm giảm điểm):\n",
    "        - Hệ số giới tính (Gender) -0.33 cho thấy có sự chênh lệch điểm số giữa các giới tính (nhóm được mã hóa là 1 có điểm thấp hơn nhóm 0).\n",
    "        - Tuổi (Age at enrollment), sinh viên nhập học càng lớn tuổi, điểm càng có xu hướng giảm nhẹ (hệ số -0.015).\n",
    "\n",
    "- **Kiểm định giả thiết (Diagnostics)**: Không có tự tương quan, giá trị Durbin-Watson 2.012 (xấp xỉ 2) là lý tưởng. Đa cộng tuyến thấp: Cond. No.: 147 nằm trong ngưỡng an toàn, không có hiện tượng đa cộng tuyến nghiêm trọng. Vấn đề phân phối chuẩn: Các chỉ số Omnibus, Jarque-Bera, Kurtosis rất cao cho thấy phần dư (residuals) không phân phối chuẩn. Tuy nhiên, với kích thước mẫu lớn (N=4424), điều này không quá ảnh hưởng đến tính vững của các hệ số hồi quy, nhưng cần lưu ý khi xét khoảng tin cậy.\n",
    "\n",
    "**Kết luận**: Mô hình mạnh và đáng tin cậy để dự báo điểm kỳ 2, trong đó kết quả học tập kỳ 1 là yếu tố dự báo then chốt nhất."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
