{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Nhập thư viện và đọc dữ liệu từ file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from scipy.stats import poisson\n",
    "\n",
    "df = pd.read_csv(\"data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Khám phá dữ liệu (Exploratory Data Analysis - EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### a. Tóm tắt thông tin dữ liệu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "cái df này nó chỉ có cột target là cat thôi vì trên uci nó đã label encode r lọc ra thành mấy cột integer r nên h đi tìm lại để tìm tương quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=[\"object\"])\n",
    "print(cat_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[\"number\"])\n",
    "print(num_cols.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_like = [col for col in df.columns if df[col].nunique() < 50]\n",
    "print(cat_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiative_columns = [\n",
    "    \"Age at enrollment\",\n",
    "    \"Curricular units 1st sem (credited)\",\n",
    "    \"Curricular units 1st sem (enrolled)\",\n",
    "    \"Curricular units 1st sem (evaluations)\",\n",
    "    \"Curricular units 1st sem (approved)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\n",
    "    \"Curricular units 2nd sem (credited)\",\n",
    "    \"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\",\n",
    "    \"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\n",
    "    \"Unemployment rate\",\n",
    "    \"Inflation rate\",\n",
    "    \"GDP\",\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 2nd sem (grade)\"\n",
    "]\n",
    "\n",
    "cat_columns = [col for col in cat_like if col not in quantiative_columns]\n",
    "ordinal_column = [\"Application order\"]\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Kiểm tra số lượng bản ghi, số lượng biến số, kiểu dữ liệu của từng biến.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Xử lý dữ liệu thiếu, dữ liệu trùng lặp (nếu có).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().sum())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### b. Phân tích thống kê mô tả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### Tính các thống kê như trung bình, trung vị, độ lệch chuẩn, tứ phân vị.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df.drop(columns=cat_columns)\n",
    "df_numeric.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram split by target\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"Admission grade\",\n",
    "    hue=\"Target\",  # separates Dropout vs Graduate\n",
    "    bins=20,  # adjust for clarity\n",
    "    kde=True,  # optional: overlay density\n",
    "    stat=\"density\",  # normalize for comparison\n",
    "    palette=[\"red\", \"green\", \"blue\"],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "plt.title(\"Admission grade distribution by Target\")\n",
    "plt.xlabel(\"Admission grade\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Trực quan hoá bằng các biểu đồ phù hợp (ít nhất 3 loại biểu đồ) để nhận"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a countplot:\n",
    "# x-axis: The outcome (Target)\n",
    "# hue: The secondary variable used to group the bars (Attendance Status)\n",
    "# palette: Uses the same color scheme as the previous example (reds/greens) for consistency\n",
    "sns.countplot(\n",
    "    data=df,\n",
    "    x=\"Target\",\n",
    "    hue=\"Daytime/evening attendance\\t\",\n",
    "    palette={\"green\", \"red\"},\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1.5,\n",
    ")\n",
    "\n",
    "# --- 3. CUSTOMIZE PLOT AESTHETICS ---\n",
    "plt.title(\n",
    "    \"Student Outcome (Target) by Attendance Status\", fontsize=16, fontweight=\"bold\"\n",
    ")\n",
    "plt.xlabel(\"Student Outcome\", fontsize=14)\n",
    "plt.ylabel(\"Count of Students\", fontsize=14)\n",
    "plt.legend(title=\"Attendance Status\", title_fontsize=\"12\", fontsize=\"10\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "attendance_col = (\n",
    "    \"Daytime/evening attendance\\t\"  # keep the tab if it's in the column name\n",
    ")\n",
    "target_col = \"Target\"\n",
    "\n",
    "# Count occurrences\n",
    "counts = df.groupby([attendance_col, target_col]).size().reset_index(name=\"count\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=counts, x=attendance_col, y=\"count\", hue=target_col)\n",
    "plt.xlabel(\"Attendance Type (0=Daytime, 1=Evening)\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.title(\"Attendance Type vs Final Target\")\n",
    "plt.legend(title=\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "this data makes sense specially for this dataset since this is A dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies. \n",
    "\n",
    "i.e. they have jobs in the day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_col = \"Daytime/evening attendance\\t\"\n",
    "target_col = \"Target\"\n",
    "\n",
    "categories = [\"Dropout\", \"Enrolled\", \"Graduate\"]\n",
    "\n",
    "daytime_counts = (\n",
    "    df[df[attendance_col] == 0][target_col].value_counts().reindex(categories)\n",
    ")\n",
    "evening_counts = (\n",
    "    df[df[attendance_col] == 1][target_col].value_counts().reindex(categories)\n",
    ")\n",
    "\n",
    "# Create two side-by-side pie charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].pie(\n",
    "    daytime_counts,\n",
    "    labels=daytime_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=[\"#ff0000\", \"#8da0cb\", \"#66c2a5\"],\n",
    ")\n",
    "axes[0].set_title(\"Daytime Attendance\")\n",
    "\n",
    "axes[1].pie(\n",
    "    evening_counts,\n",
    "    labels=evening_counts.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=[\"#ff0000\", \"#8da0cb\", \"#66c2a5\"],\n",
    ")\n",
    "axes[1].set_title(\"Evening Attendance\")\n",
    "\n",
    "plt.suptitle(\"Target Distribution by Attendance Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "this one shows percantage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Same thing but for scholarship (this should be obvious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_col = \"Scholarship holder\"  # keep the tab if it's in the column name\n",
    "target_col = \"Target\"\n",
    "\n",
    "# Count occurrences\n",
    "counts = df.groupby([var_col, target_col]).size().reset_index(name=\"count\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=counts, x=var_col, y=\"count\", hue=target_col)\n",
    "plt.xlabel(\"Scholarship holder (0=No, 1=Yes)\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.title(\"Scholarship Type vs Final Target\")\n",
    "plt.legend(title=\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_col = \"Scholarship holder\"\n",
    "target_col = \"Target\"\n",
    "\n",
    "categories = [\"Dropout\", \"Enrolled\", \"Graduate\"]\n",
    "\n",
    "no = df[df[var_col] == 0][target_col].value_counts().reindex(categories)\n",
    "yes = df[df[var_col] == 1][target_col].value_counts().reindex(categories)\n",
    "\n",
    "# Create two side-by-side pie charts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].pie(\n",
    "    no,\n",
    "    labels=no.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=[\"#ff0000\", \"#8da0cb\", \"#66c2a5\"],\n",
    ")\n",
    "axes[0].set_title(\"Non scholarship holders\")\n",
    "\n",
    "axes[1].pie(\n",
    "    yes,\n",
    "    labels=yes.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    colors=[\"#ff0000\", \"#8da0cb\", \"#66c2a5\"],\n",
    ")\n",
    "axes[1].set_title(\"Scholarship holders\")\n",
    "\n",
    "plt.suptitle(\"Target Distribution by Scholarship Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### c. Phát hiện dữ liệu ngoại lai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Sử dụng IQR (Interquartile Range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "df_numeric.boxplot(rot=90)  # rot=90 to rotate x-axis labels\n",
    "plt.title(\"Boxplots of All Numeric Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "**investigating gdp, inflation and unemployment**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[[\"GDP\", \"Unemployment rate\", \"Inflation rate\"]]\n",
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Knowing that the data comes from the Instituto Politécnico de Portalegre (IPP) in Portugal directly confirms two key points that validate our previous investigation:\n",
    "\n",
    "Country: The economic data is relevant to Portugal.\n",
    "\n",
    "Context: The data is from a Portuguese polytechnic institute during a specific time period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "| Metric            | Range (Min to Max) | Confirmed Context                                                                 | Conclusion                                           |\n",
    "|------------------|-------------------|----------------------------------------------------------------------------------|----------------------------------------------------|\n",
    "| Unemployment Rate | 7.6% to 16.2%     | Matches the severe economic crisis and subsequent recovery in Portugal (roughly 2008–2018). | Plausible. The highest values are likely accurate historical peaks. |\n",
    "| Inflation Rate    | -0.8% to 3.7%     | Matches Portugal's largely stable, low-inflation environment during that period, including some deflationary dips. | Plausible. Very stable and reliable data.         |\n",
    "| GDP               | -4.06 to 3.51     | Matches Portugal's sharp recessionary decline followed by years of recovery growth. | Plausible. Represents real economic volatility.   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "phương pháp xử lý đề xuất (cho mấy cột trên với lại mấy cái course)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "***!!!Square Root Transformation!!!***\n",
    "might or might or have to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "You only transform the distribution (log/square root) for features that are highly skewed (like GDP and Curricular Units). You must apply scaling to every continuous numeric column to ensure no single variable dominates your model due to its large value range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "***NHẬN XÉT TỔNG QUAN SO FAR***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## 2. Phân tích phân phối xác suất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### Chọn ít nhất hai biến số quan trọng và kiểm tra xem nó có tuân theo phân phối xác suất nào không (chuẩn, Poisson, exponential…) sử dụng biểu đồ phù hợp để minh hoạ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Application order\"\n",
    "data = df[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)  # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color=\"skyblue\", stat=\"density\")\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, \"r\", linewidth=2)\n",
    "\n",
    "plt.title(f\"{col} (mu={mu:.2f}, std={std:.2f})\")\n",
    "plt.xlabel(col)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Admission grade\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)  # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color=\"skyblue\", stat=\"density\")\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, \"r\", linewidth=2)\n",
    "\n",
    "plt.title(f\"{col} (mu={mu:.2f}, std={std:.2f})\")\n",
    "plt.xlabel(col)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Age at enrollment\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)  # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color=\"skyblue\", stat=\"density\")\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, \"r\", linewidth=2)\n",
    "\n",
    "plt.title(f\"{col} (mu={mu:.2f}, std={std:.2f})\")\n",
    "plt.xlabel(col)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Curricular units 1st sem (grade)\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)  # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color=\"skyblue\", stat=\"density\")\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, \"r\", linewidth=2)\n",
    "\n",
    "plt.title(f\"{col} (mu={mu:.2f}, std={std:.2f})\")\n",
    "plt.xlabel(col)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Curricular units 2nd sem (grade)\"\n",
    "data = df_numeric[col].dropna()  # drop NaN values\n",
    "mu, std = norm.fit(data)  # fit a normal distribution\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Histogram\n",
    "sns.histplot(data, bins=20, kde=False, color=\"skyblue\", stat=\"density\")\n",
    "# Plot Gaussian\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, \"r\", linewidth=2)\n",
    "\n",
    "plt.title(f\"{col} (mu={mu:.2f}, std={std:.2f})\")\n",
    "plt.xlabel(col)\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vì là biến rời rạc, ta so sánh Histogram với các điểm xác suất Poisson\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(\n",
    "    df[\"Curricular units 1st sem (approved)\"],\n",
    "    discrete=True,\n",
    "    stat=\"density\",\n",
    "    color=\"lightgreen\",\n",
    ")\n",
    "mu_pois = df[\"Curricular units 1st sem (approved)\"].mean()\n",
    "x_pois = np.arange(0, 15)\n",
    "p_pois = poisson.pmf(x_pois, mu_pois)\n",
    "plt.plot(x_pois, p_pois, \"ro-\", linewidth=2, label=f\"Poisson Fit (mean={mu_pois:.1f})\")\n",
    "plt.title(f\"Units Approved 1st Sem (mu = {mu_pois:.2f})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## 3. Kiểm định giả thuyết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày các kiểm định thống kê sau: t-test, Chi-square và ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### b. Đề xuất hai câu hỏi nghiên cứu có thể kiểm định bằng dữ liệu cho bộ dữ liệu đã chọn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "câu hỏi: giới tính khác nhau có ảnh hưởng đến cái dropout rate hay ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Tạo bảng tần số (contingency table)\n",
    "table = pd.crosstab(df[\"Gender\"], df[\"Target\"])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, expected = chi2_contingency(table)\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Expected frequencies:\\n\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "Null hypothesis (H0): Giới tính và kết quả học tập không liên quan (độc lập)\n",
    "\n",
    "Alternative hypothesis (H1): Có sự phụ thuộc giữa giới tính và kết quả học tập\n",
    "\n",
    "Nếu p < 0.05 → bác bỏ H0 → có sự khác biệt có ý nghĩa\n",
    "\n",
    "Nếu p >= 0.05 → không bác bỏ H0 → không có bằng chứng về sự khác biệt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "Vì p << 0.05, chúng ta bác bỏ H0 → kết luận:\n",
    "\n",
    "Có sự khác biệt rất rõ ràng về kết quả học tập giữa nam và nữ. Giới tính và Target không độc lập trong dữ liệu này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_norm = table.div(table.sum(axis=1), axis=0)  # chuyển sang tỉ lệ %\n",
    "table_norm.plot(kind=\"bar\", stacked=True, figsize=(8, 5), colormap=\"Set2\")\n",
    "\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xlabel(\"Gender (0=Male, 1=Female)\")\n",
    "plt.title(\"Target distribution by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Bảng tỉ lệ %\n",
    "table_percent = table.div(table.sum(axis=1), axis=0) * 100\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(table_percent, annot=True, fmt=\".1f\", cmap=\"YlGnBu\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Gender (0=Male, 1=Female)\")\n",
    "plt.title(\"Heatmap of Target distribution by Gender (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(\n",
    "    data=df,\n",
    "    x=\"Admission grade\",\n",
    "    hue=\"Gender\",\n",
    "    bins=20,\n",
    "    kde=True,\n",
    "    palette=[\"blue\", \"orange\"],\n",
    "    alpha=0.6,\n",
    "    stat=\"density\",\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of Admission Grade by Gender\")\n",
    "plt.xlabel(\"Admission Grade\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(title=\"Gender\", labels=[\"Female\", \"Male\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "wowza! kết quả cho thấy có sự chênh lệch rõ ràng giữa hai giới tính"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "#### Kiểm định khác biệt độ tuồi giữa các nhóm target bằng anova ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "anova cần mấy biến tuân theo phân phối chuẩn, nên t đi check coi chuẩn ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "from scipy.stats import levene\n",
    "\n",
    "groups = df.groupby(\"Target\")[\"Age at enrollment\"]\n",
    "\n",
    "for name, group_data in groups:\n",
    "    stat, p = shapiro(group_data.dropna())  # drop NA values\n",
    "    print(f\"{name}: W={stat:.3f}, p={p:.3f}\")\n",
    "\n",
    "groups = [group.dropna() for name, group in df.groupby(\"Target\")[\"Age at enrollment\"]]\n",
    "\n",
    "stat, p = levene(*groups)\n",
    "print(f\"Levene’s test: W={stat:.3f}, p={p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "⚠️ This violates the normality assumption for ANOVA.\n",
    "\n",
    "⚠️ This violates the homogeneity of variance assumption for ANOVA.\n",
    "\n",
    "Since both normality and equal variance assumptions are violated, one-way ANOVA is NOT appropriate here.\n",
    "\n",
    "✅ Correct approach:\n",
    "Use a non-parametric alternative like Kruskal-Wallis test, which does not assume normality or equal variances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "dropout_age = df[df[\"Target\"] == \"Dropout\"][\"Age at enrollment\"]\n",
    "enrolled_age = df[df[\"Target\"] == \"Enrolled\"][\"Age at enrollment\"]\n",
    "graduate_age = df[df[\"Target\"] == \"Graduate\"][\"Age at enrollment\"]\n",
    "\n",
    "stat, p = kruskal(dropout_age, enrolled_age, graduate_age)\n",
    "print(f\"Kruskal-Wallis test: H={stat:.3f}, p={p:.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "Since p << 0.05, you reject the null hypothesis. This means there is a statistically significant difference between at least one pair of your groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "Minh họa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for plotting\n",
    "plot_df = df[[\"Target\", \"Age at enrollment\"]].dropna()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(x=\"Target\", y=\"Age at enrollment\", data=plot_df, palette=\"Set3\")\n",
    "plt.title(\"Age at Enrollment by Target Group\")\n",
    "plt.ylabel(\"Age at Enrollment\")\n",
    "plt.xlabel(\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "Kết luận: Dữ liệu cho thấy mối quan hệ nghịch đảo giữa độ tuổi nhập học và khả năng tốt nghiệp. Về mặt thống kê, những sinh viên nhập học ở độ tuổi truyền thống sớm hơn có khả năng hoàn thành chương trình học cao hơn nhiều so với những sinh viên nhập học muộn hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "## 4. Phân tích tương quan giữa các biến"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày hệ số tương quan Pearson và Spearman."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "Pearson correlation coefficient (PCC) is a correlation coefficient that measures linear correlation between two sets of data. It is the ratio between the covariance of two variables and the product of their standard deviations; thus, it is essentially a normalized measurement of the covariance, such that the result always has a value between −1 and 1. As a simple example, one would expect the age and height of a sample of children from a school to have a Pearson correlation coefficient significantly greater than 0, but less than 1 (as 1 would represent an unrealistically perfect correlation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "Spearman's rank correlation coefficient or Spearman's ρ is a number ranging from -1 to 1 that indicates how strongly two sets of ranks are correlated. It could be used in a situation where one only has ranked data, such as a tally of gold, silver, and bronze medals. If a statistician wanted to know whether people who are high ranking in sprinting are also high ranking in long-distance running, they would use a Spearman rank correlation coefficient.It assesses how well the relationship between two variables can be described using a monotonic function.\n",
    "\n",
    "The Spearman correlation between two variables is equal to the Pearson correlation between the rank values of those two variables; while Pearson's correlation assesses linear relationships, Spearman's correlation assesses monotonic relationships (whether linear or not). If there are no repeated data values, a perfect Spearman correlation of +1 or −1 occurs when each of the variables is a perfect monotone function of the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "#### b. Áp dụng tính hệ số tương quan Pearson và Spearman giữa các biến số trong bộ dữ liệu đã chọn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_pearson = df[quantiative_columns].corr(method=\"pearson\")\n",
    "corr_spearman = df[quantiative_columns].corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "#### c. Sử dụng biểu đồ phù hợp để trực quan hóa mối quan hệ giữa các biến. (Heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for Pearson\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_pearson, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Pearson Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Heatmap for Spearman\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_spearman, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Spearman Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "#### d. Đưa ra nhận xét về ý nghĩa thực tiễn của các mối tương quan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "- **Tính kế thừa và dự báo mạnh mẽ (Quan trọng nhất):** Tương quan giữa Học kỳ 1 và Học kỳ 2 là rất cao (màu đỏ đậm, hệ số > 0.9). Kết quả học tập kỳ đầu là chỉ báo dự báo chính xác nhất cho kỳ sau. Sinh viên có xu hướng duy trì phong độ ổn định; ai học tốt kỳ 1 thường sẽ học tốt kỳ 2 và ngược lại. Nhà trường có thể dùng kết quả kỳ 1 để sớm phát hiện sinh viên cần hỗ trợ.\n",
    "- **Mối quan hệ giữa Nỗ lực và Kết quả:** Có sự tương quan thuận chặt chẽ giữa số môn đăng ký/tham gia đánh giá (enrolled/evaluations) và số môn đạt (approved/credited). Mức độ tích cực tham gia học tập và thi cử quyết định lớn đến kết quả đầu ra. Tuy nhiên, hệ số không phải tuyệt đối (1.0), cho thấy việc \"chăm đi thi\" là điều kiện cần nhưng chưa đủ, vẫn tồn tại tỷ lệ rớt môn nhất định.\n",
    "- **Yếu tố Kinh tế vĩ mô không tác động trực tiếp:** Các chỉ số GDP, Lạm phát, Thất nghiệp có hệ số tương quan gần bằng 0 (màu xanh nhạt/trắng) với các biến kết quả học tập.Trong phạm vi dữ liệu này, bối cảnh kinh tế bên ngoài không ảnh hưởng đáng kể đến thành tích học tập của cá nhân sinh viên. Việc học kém hay giỏi phụ thuộc vào yếu tố nội tại hơn là môi trường kinh tế vĩ mô.\n",
    "- **Tuổi tác không phải là rào cản:** Biến \"Age at enrollment\" có tương quan rất thấp với các kết quả học tập. Độ tuổi nhập học (già hay trẻ) không quyết định thành công hay thất bại trong môi trường đại học.\n",
    "\n",
    "***Tóm lại:*** Để cải thiện chất lượng đào tạo, nên tập trung giám sát kết quả ngay từ Học kỳ 1 và khuyến khích sinh viên tham gia đầy đủ các bài đánh giá, thay vì lo ngại về các yếu tố nhân khẩu học (tuổi) hay kinh tế bên ngoài."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "## 5. Hồi quy đa biến (Multiple Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### a. Tìm hiểu và trình bày lý thuyết về Hồi quy đa biến."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "Hồi quy đa biến là một kĩ thuật thống kê sử dụng nhiều biến độc lập (các thuộc tính) để dự đoán kết quả của một biến phụ thuốc, các biến độc lập này lý tưởng sẽ có ý nghĩa để giải thích sẽ mô hình huấn luyện này. Mục đích của hồi quy đa biến là mô hình hóa mối tương quan tuyến tính giữa các biến độc lập với biến phụ thuộc. Về cơ bản, hồi quy đa biến là một hồi quy tuyến tính vì nó bao gồm nhiều hơn một biến độc lập."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "### b. Xây dựng và đánh giá mô hình hồi quy tuyến tính đa biến nhằm dự đoán một biến phụ thuộc (biến mục tiêu) dựa trên nhiều biến độc lập trong bộ dữ liệu đã chọn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "Ở đây ta định nghĩa rằng biến phụ thuộc là Curricular units 2nd sem (grade) (điểm bình quân học kỳ 2 từ 0 tới 20) và các biến còn lại là biến phụ thuộc để minh họa cho hồi quy đa biến do Target của tập dữ liệu là biến định tính (nghỉ học, đang học, tốt nghiệp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "Chúng tôi đã chủ động tránh việc áp dụng One-Hot Encoding toàn phần cho các đặc trưng có tính đa dạng cao (high-cardinality) – như Nghề nghiệp và Khóa học – để ngăn chặn 'Lời nguyền của số chiều' (The Curse of Dimensionality).\n",
    "\n",
    "Rất nhiều giá trị phân loại trong số này có độ hỗ trợ (Support) thấp (chiếm dưới 1% tập dữ liệu), tạo ra các 'Đặc trưng thưa' (Sparse Features) dẫn đến việc mô hình mất ổn định và bị quá khớp (overfitting).\n",
    "\n",
    "Thay vào đó, chúng tôi ưu tiên các đặc trưng có độ hỗ trợ cao, bao quát được toàn bộ tổng thể. Điều này đảm bảo mô hình sẽ học được các quy luật hành vi tổng quát thay vì chỉ 'học vẹt' (ghi nhớ) các nhóm nhỏ lẻ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "Support là tỉ lệ giữa độ tần suất của một biến với cả tập dữ liệu. Nó được sử dụng để tìm một tập các biến xuất hiện có thường xuyên hay không trong tập dữ liệu. Công thức:\n",
    "$$ \\text{Support}(X) = \\frac{\\text{Number of transactions containing itemset X}}{\\text{Total number of transactions}} $$\n",
    "Sau đây chúng tôi sẽ thử nghiệm và áp dụng công thức này lên tất cả các cột trong tập dữ liệu để xét xem thử mức độ thưa thớt của các cột trên tập dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Continuous Columns\n",
    "continuous_cols = [\n",
    "    \"Curricular units 1st sem (grade)\",\n",
    "    \"Curricular units 2nd sem (grade)\",\n",
    "    \"Curricular units 1st sem (enrolled)\",\n",
    "    \"Curricular units 2nd sem (enrolled)\",\n",
    "    \"Curricular units 1st sem (evaluations)\",\n",
    "    \"Curricular units 2nd sem (evaluations)\",\n",
    "    \"Curricular units 1st sem (approved)\",\n",
    "    \"Curricular units 2nd sem (approved)\",\n",
    "    \"Curricular units 1st sem (credited)\",\n",
    "    \"Curricular units 2nd sem (credited)\",\n",
    "    \"Curricular units 1st sem (without evaluations)\",\n",
    "    \"Curricular units 2nd sem (without evaluations)\",\n",
    "    \"Age at enrollment\",\n",
    "    \"Unemployment rate\",\n",
    "    \"Inflation rate\",\n",
    "    \"GDP\",\n",
    "    \"Application order\",\n",
    "    \"Previous qualification (grade)\",\n",
    "    \"Admission grade\",\n",
    "]\n",
    "\n",
    "# 2. Dynamically identify ALL other columns (The \"Hidden\" Categories)\n",
    "df.columns = df.columns.str.strip()\n",
    "categorical_candidates = [col for col in df.columns if col not in continuous_cols]\n",
    "\n",
    "# 3. Run the Audit\n",
    "audit_data = []\n",
    "\n",
    "for col in categorical_candidates:\n",
    "    # Get the distribution percentages\n",
    "    counts = df[col].value_counts(normalize=True) * 100\n",
    "\n",
    "    total_categories = len(counts)\n",
    "    rare_categories = len(counts[counts < 1.0])\n",
    "\n",
    "    if total_categories > 0:\n",
    "        sparsity_rate = (rare_categories / total_categories) * 100  # Support value\n",
    "    else:\n",
    "        sparsity_rate = 0\n",
    "\n",
    "    audit_data.append(\n",
    "        {\n",
    "            \"Feature\": col,\n",
    "            \"Total Cats\": total_categories,\n",
    "            \"Rare Cats (<1%)\": rare_categories,\n",
    "            \"Sparsity Rate (%)\": round(sparsity_rate, 1),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# 4. Sort and Display\n",
    "audit_df = pd.DataFrame(audit_data).sort_values(by=\"Sparsity Rate (%)\", ascending=False)\n",
    "\n",
    "# FIX: Explicitly remove any lingering tabs in the Feature column before plotting\n",
    "audit_df[\"Feature\"] = audit_df[\"Feature\"].astype(str).str.replace(\"\\t\", \"\", regex=False)\n",
    "\n",
    "print(f\"--- FULL DATASET AUDIT ({len(categorical_candidates)} Columns Scanned) ---\")\n",
    "print(audit_df)\n",
    "\n",
    "# 5. Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.barplot(\n",
    "    x=\"Sparsity Rate (%)\",\n",
    "    y=\"Feature\",\n",
    "    data=audit_df,\n",
    "    palette=\"magma\",\n",
    "    hue=\"Feature\",\n",
    "    legend=False,\n",
    ")\n",
    "\n",
    "plt.title(\n",
    "    'Sparsity Audit: Which columns are mostly \"Junk\"?', fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# FIX: Removed plt.legend() because it was empty and causing a warning\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "- **Lý do ưu tiên các Đặc trưng có \"Độ thưa thấp\" (0%)**\n",
    "    - Quá trình kiểm tra cho thấy các đặc trưng có số lượng phân loại lớn (high-cardinality) như Nationality (Quốc tịch) và Occupation (Nghề nghiệp) bị thưa thớt nghiêm trọng, trong đó hơn 80% các danh mục xuất hiện trong dưới 1% tập dữ liệu. Việc đưa các đặc trưng này vào sẽ tạo ra hai vấn đề nghiêm trọng:\n",
    "    - Quá khớp (Overfitting): Mô hình sẽ \"ghi nhớ\" các danh mục hiếm (ví dụ: một công việc cụ thể chỉ có 3 sinh viên làm) thay vì học các mẫu tổng quát hóa.\n",
    "    - Không ổn định (Instability): Các hệ số được suy ra từ các mẫu có kích thước quá nhỏ sẽ không đáng tin cậy về mặt thống kê.\n",
    "\n",
    "Vì tập dữ liệu này đã lớn sẵn và khi được phân rã các biến định tính bằng one hot encoding sẽ làm cho tập dữ liệu càng rối thêm. Để làm cho mô hình đơn giản, dễ hiểu và không quá dài dòng thì chúng tôi giới hạn danh sách ứng viên vào các đặc trưng có độ thưa 0% (Độ hỗ trợ cao/High Support), chúng tôi đảm bảo rằng mọi biến đều áp dụng cho một phần lớn của tập hợp sinh viên. Điều này đảm bảo mô hình học được các mẫu hành vi toàn cục thay vì nhiễu cục bộ.\n",
    "\n",
    "- **Loại trừ Biến \"Target\" (Rò rỉ dữ liệu)**: Mặc dù biến Target (Tốt nghiệp/Bỏ học) xuất hiện trong danh sách Độ thưa 0%, nó bị loại trừ khỏi danh sách ứng viên do vấn đề Rò rỉ dữ liệu (Data Leakage). Target đại diện cho kết quả cuối cùng của văn bằng (thông tin tương lai). Trong kịch bản dự đoán thực tế (ví dụ: dự đoán điểm số khi bắt đầu Học kỳ 2), chúng ta không thể biết liệu sinh viên đó có tốt nghiệp nhiều năm sau hay không. Việc sử dụng Target để dự đoán Điểm học kỳ 2 sẽ thổi phồng độ chính xác một cách nhân tạo bằng thông tin không có sẵn tại thời điểm dự đoán.\n",
    "\n",
    "- **Về GDP**: Chúng tôi giữ lại GDP (và các chỉ số kinh tế liên quan) làm ứng viên. Khác với Target, các giá trị này thường được ghi nhận tại thời điểm nhập học hoặc là các trung bình kinh tế vĩ mô hàng năm đã biết trong suốt học kỳ. Chúng cung cấp bối cảnh môi trường hợp lệ mà không vi phạm logic thời gian.\n",
    "\n",
    "- **Danh sách Ứng viên Sơ bộ (Trước khi Kiểm định Thống kê)**: Dựa trên tiêu chí Độ thưa 0%, chúng tôi giữ lại toàn bộ danh sách các biến an toàn (High Support) dưới đây để tiến hành các bước kiểm định tiếp theo:\n",
    "    - Nhóm Tài chính: Tuition fees up to date, Debtor, Scholarship holder.\n",
    "    - Nhóm Nhân khẩu học: Age at enrollment, Gender, Displaced, International.\n",
    "    - Nhóm Hành vi/Khác: Daytime/evening attendance, Educational special needs.\n",
    "    - Nhóm Kinh tế/Học thuật: GDP, Curricular units 1st sem (grade).\n",
    "\n",
    "- **Kế hoạch Kiểm định Thống kê (Validation Plan)**: Để gạn lọc danh sách sơ bộ này, chúng tôi sẽ áp dụng hai bước kiểm tra thống kê cho tất cả các ứng viên trong danh sách trên:\n",
    "    - Bước 1: Kiểm tra VIF để Phát hiện các biến bị dư thừa (Multicollinearity). Chúng tôi sẽ kiểm tra ván đề đa cộng tuyến của các ứng cử viên (biến có thể sẽ được chọn chính thức và được sử dụng trong mô hình ols sau này) này và loại bỏ (nếu có) các thuộc với giá trị VIF cao (lớn hơn 5).\n",
    "    - Bước 2: Chạy mô hình OLS với tất cả ứng viên còn lại. Nếu một biến có P-value > 0.05, nó chứng tỏ biến đó không đóng góp thông tin giá trị khi đã có các biến khác, và sẽ bị loại bỏ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "Phát hiện đa cộng tuyến trước khi áp dụng các biến vào mô hình hồi quy và loại bỏ các ứng cử viên được xem là không quan trọng về mặt thống kê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "Vì trong các biến có giá tị liên tục, có một vài là rò rỉ dữ liệu, các cột liên quan tới học kỳ hai:   \n",
    "- **\"Curricular units 2nd sem (enrolled)\"**: Giữ cột này vì đây là thông tin có thể biết được khi dự đoán, đây là số môn mà học sinh đã tham gia trong học kỳ hai.\n",
    "- **\"Curricular units 2nd sem (evaluations)\"**: Bỏ cột này vì đây là số lần thi (kể cả thi lại) mà học sinh đã tham gia sau học kì hai, giá trị này không thể biết được trước khi thi học kỳ hai.\n",
    "- **\"Curricular units 2nd sem (without evaluations)\"**: Cũng như cột ngay bên trên, bỏ cột này vì đây là số lần thi mà học sinh đã không tham gia sau học kì hai vì lý do nào đó (ví dụ: lý do cá nhân bệnh, sốt, quên, hay là không đủ điều kiện dự thi), giá trị này không thể biết được trước khi thi học kỳ hai.\n",
    "- **\"Curricular units 2nd sem (approved)\"**: Đây cũng là cột dữ liệu rò rỉ, tổng số môn học đậu (kể cả miễn hay là phải thi) của sinh viên là không thể nào biết được trước khi học kỳ hai kết thúc.\n",
    "- **\"Curricular units 2nd sem (credited)\"**: Giữ cột này do đây là số môn mà học sinh được miễn khi học kỳ hai mới bắt đầu.\n",
    "Và \"Curricular units 2nd sem (grade)\" là biến phụ thuộc chúng tôi sẽ dự đoán nên sẽ được loại bỏ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "Vì các biến được chọn làm ứng cử viên đều là biến nhị phân (Binary Variables), chỉ có 2 giá trị (0 và 1). Với biến 0/1, hồi quy hiểu đơn giản là \"tắt\" hoặc \"bật\". Hiệu ứng của nó chỉ là cộng hoặc trừ một hằng số vào kết quả. Label Encoding được áp dụng sẵn trên tập dữ liệu là hoàn toàn ổn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# We will check vif to avoid multicolinearity\n",
    "# 1. Define list of 0% sparsity features\n",
    "redundancy_columns_check = [\n",
    "    \"Daytime/evening attendance\",\n",
    "    \"Displaced\",\n",
    "    \"Educational special needs\",\n",
    "    \"Debtor\",\n",
    "    \"Tuition fees up to date\",\n",
    "    \"Gender\",\n",
    "    \"Scholarship holder\",\n",
    "    \"International\",\n",
    "]\n",
    "\n",
    "redundancy_df_check = df[redundancy_columns_check + continuous_cols]\n",
    "\n",
    "redundancy_df_check.drop(\n",
    "    [\n",
    "        \"Curricular units 2nd sem (grade)\",\n",
    "        \"Curricular units 2nd sem (evaluations)\",\n",
    "        \"Curricular units 2nd sem (without evaluations)\",\n",
    "        \"Curricular units 2nd sem (approved)\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "# 2. Add a constant (intercept) for the VIF calculation\n",
    "# (statsmodels OLS requires an intercept to calculate VIF correctly)\n",
    "X_vif = redundancy_df_check.assign(const=1)\n",
    "\n",
    "# 3. Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_vif.columns\n",
    "vif_data[\"VIF\"] = [\n",
    "    variance_inflation_factor(X_vif.values, i) for i in range(len(X_vif.columns))\n",
    "]\n",
    "\n",
    "# 4. Sort and Display\n",
    "print(vif_data.sort_values(by=\"VIF\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "Ở bước tiếp theo, chúng tôi sẽ tạo một hàm để xóa bỏ một biến với giá vif cao nhất lớn hơn 5 cho tới khi không còn biến nào lớn hơn 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_vif_features(df, threshold=5.0):\n",
    "    \"\"\"\n",
    "    Iteratively removes features with a VIF greater than the threshold\n",
    "    and prints the final VIF table.\n",
    "    \"\"\"\n",
    "    # Create a copy and ensure numeric data only\n",
    "    df_output = df.copy()\n",
    "    df_output = df_output.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "    while True:\n",
    "        # Add constant\n",
    "        df_with_const = add_constant(df_output)\n",
    "        # Calculate VIF for current features\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"feature\"] = df_with_const.columns\n",
    "        vif_data[\"VIF\"] = [\n",
    "            variance_inflation_factor(df_with_const.values, i)\n",
    "            for i in range(df_with_const.shape[1])\n",
    "        ]\n",
    "\n",
    "        # Filter out the 'const' row so we don't try to drop it\n",
    "        vif_data = vif_data[vif_data[\"feature\"] != \"const\"]\n",
    "\n",
    "        # Get the feature with the maximum VIF\n",
    "        max_vif = vif_data[\"VIF\"].max()\n",
    "\n",
    "        # Check against threshold\n",
    "        if max_vif > threshold:\n",
    "            # Identify feature to drop\n",
    "            max_feature = vif_data.sort_values(\"VIF\", ascending=False).iloc[0][\n",
    "                \"feature\"\n",
    "            ]\n",
    "            print(f\"Dropping '{max_feature}' (VIF: {max_vif:.2f})\")\n",
    "            df_output = df_output.drop(columns=[max_feature])\n",
    "        else:\n",
    "            # df_output[]\n",
    "            # STOP CONDITION MET: Print the final table\n",
    "            print(\"\\nFinal VIF Values:\")\n",
    "            print(\"-----------------\")\n",
    "            print(vif_data.sort_values(\"VIF\", ascending=False))\n",
    "            break\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "df_cleaned = remove_high_vif_features(redundancy_df_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "Sau khi loại bỏ biến cho tới khi không còn giá trị vif lớn hơn 5, kết quả cho thấy tất cả thuộc tính đều có giá trị vif rất thấp nên tạm thời có thể đưa vô mô hình ols một cách an toàn. Sau đó chúng tôi sẽ huấn luyện mô hình bằng các ứng cử viên này, dựa vào kết quả mô hình, chúng tôi tập trung vào giá trị P|t| để xác định nếu các biến có thực sự mang ý nghĩa thống kê hay không và các biến với giá trị ấy lớn hơn 0.05 thì sẽ được loại bỏ, các biến còn lại sau bước tiếp theo chính là biến được sử dụng trong mô hình ols, nó sẽ thực sự có ý nghĩa thống kê và dự đoán và chúng tôi có thể giải thích được mô hình ấy, đây là một kĩ thuật gọi là Backward Elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# We create a model with all these candidates\n",
    "X_challenger = sm.add_constant(df_cleaned)\n",
    "y = df[\"Curricular units 2nd sem (grade)\"]\n",
    "\n",
    "model_challenger = sm.OLS(y, X_challenger).fit()\n",
    "\n",
    "print(\"--- EVIDENCE B: The 'Challenger' Model Results ---\")\n",
    "print(model_challenger.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "Chúng tôi sẽ tập trung vào cột P>|t|, nếu giá trị hơn 0.05 thì biến sẽ không đáng kể về mặt thống kê và sẽ được loại bỏ ra khỏi mô hình hồi quy đa biến OLS.\n",
    "\n",
    "<table>\n",
    "<tr><th>Variable</th><th>coef</th><th>std err</th><th>t</th><th>P>|t|</th><th>[0.025</th><th>0.975]</th></tr>\n",
    "<tr><td>const</td><td>0.4475</td><td>0.610</td><td>0.733</td><td>0.464</td><td>-0.749</td><td>1.644</td></tr>\n",
    "<tr><td>Daytime/evening attendance</td><td>-0.4126</td><td>0.154</td><td>-2.671</td><td>0.008</td><td>-0.715</td><td>-0.110</td></tr>\n",
    "<tr><td>Displaced</td><td>-0.0273</td><td>0.095</td><td>-0.288</td><td>0.774</td><td>-0.213</td><td>0.159</td></tr>\n",
    "<tr><td>Educational special needs</td><td>-0.1645</td><td>0.392</td><td>-0.420</td><td>0.675</td><td>-0.933</td><td>0.604</td></tr>\n",
    "<tr><td>Debtor</td><td>-0.3410</td><td>0.146</td><td>-2.339</td><td>0.019</td><td>-0.627</td><td>-0.055</td></tr>\n",
    "<tr><td>Tuition fees up to date</td><td>1.2097</td><td>0.147</td><td>8.246</td><td>0.000</td><td>0.922</td><td>1.497</td></tr>\n",
    "<tr><td>Gender</td><td>-0.2665</td><td>0.092</td><td>-2.898</td><td>0.004</td><td>-0.447</td><td>-0.086</td></tr>\n",
    "<tr><td>Scholarship holder</td><td>0.3214</td><td>0.101</td><td>3.170</td><td>0.002</td><td>0.123</td><td>0.520</td></tr>\n",
    "<tr><td>International</td><td>0.0638</td><td>0.270</td><td>0.236</td><td>0.813</td><td>-0.465</td><td>0.593</td></tr>\n",
    "<tr><td>Curricular units 1st sem (grade)</td><td>0.8266</td><td>0.011</td><td>74.270</td><td>0.000</td><td>0.805</td><td>0.848</td></tr>\n",
    "<tr><td>Curricular units 2nd sem (enrolled)</td><td>0.2051</td><td>0.031</td><td>6.578</td><td>0.000</td><td>0.144</td><td>0.266</td></tr>\n",
    "<tr><td>Curricular units 1st sem (evaluations)</td><td>-0.0110</td><td>0.014</td><td>-0.757</td><td>0.449</td><td>-0.039</td><td>0.017</td></tr>\n",
    "<tr><td>Curricular units 2nd sem (credited)</td><td>-0.0114</td><td>0.033</td><td>-0.351</td><td>0.726</td><td>-0.075</td><td>0.053</td></tr>\n",
    "<tr><td>Curricular units 1st sem (without evaluations)</td><td>-0.0191</td><td>0.065</td><td>-0.294</td><td>0.768</td><td>-0.146</td><td>0.108</td></tr>\n",
    "<tr><td>Age at enrollment</td><td>-0.0335</td><td>0.007</td><td>-4.852</td><td>0.000</td><td>-0.047</td><td>-0.020</td></tr>\n",
    "<tr><td>Unemployment rate</td><td>-0.0154</td><td>0.017</td><td>-0.898</td><td>0.369</td><td>-0.049</td><td>0.018</td></tr>\n",
    "<tr><td>Inflation rate</td><td>-0.0360</td><td>0.031</td><td>-1.176</td><td>0.240</td><td>-0.096</td><td>0.024</td></tr>\n",
    "<tr><td>GDP</td><td>0.0526</td><td>0.020</td><td>2.589</td><td>0.010</td><td>0.013</td><td>0.092</td></tr>\n",
    "<tr><td>Application order</td><td>-0.0464</td><td>0.035</td><td>-1.321</td><td>0.187</td><td>-0.115</td><td>0.022</td></tr>\n",
    "<tr><td>Previous qualification (grade)</td><td>-0.0059</td><td>0.004</td><td>-1.498</td><td>0.134</td><td>-0.014</td><td>0.002</td></tr>\n",
    "<tr><td>Admission grade</td><td>0.0082</td><td>0.004</td><td>2.277</td><td>0.023</td><td>0.001</td><td>0.015</td></tr>\n",
    "</table>\n",
    "\n",
    "Candidates for Removal (The \"Cleanup List\"):\n",
    "\n",
    "Displaced (0.774) → Drop.\n",
    "\n",
    "Educational special needs (0.675) → Drop.\n",
    "\n",
    "International (0.813) → Drop.\n",
    "\n",
    "Curricular units 1st sem (evaluations) (0.449) → Drop.\n",
    "\n",
    "Curricular units 2nd sem (credited) (0.726) → Drop.\n",
    "\n",
    "Curricular units 1st sem (without evaluations) (0.768) → Drop.\n",
    "\n",
    "Unemployment rate (0.369) → Drop.\n",
    "\n",
    "Inflation rate (0.240) → Drop.\n",
    "\n",
    "Application order (0.187) → Drop.\n",
    "\n",
    "Previous qualification (grade) (0.134) → Drop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "Sau đó chúng tôi sẽ huấn luyện lại mô hình với các biến có ý nghĩa thống kê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Evidence-Based Feature List\n",
    "# - Low Sparsity (Stable)\n",
    "# - No Leakage (Realistic)\n",
    "# - Statistically Significant (Useful)\n",
    "df_cleaned.drop(\n",
    "    [\n",
    "        \"Displaced\",\n",
    "        \"Educational special needs\",\n",
    "        \"International\",\n",
    "        \"Curricular units 1st sem (evaluations)\",\n",
    "        \"Curricular units 2nd sem (credited)\",\n",
    "        \"Curricular units 1st sem (without evaluations)\",\n",
    "        \"Unemployment rate\",\n",
    "        \"Inflation rate\",\n",
    "        \"Application order\",\n",
    "        \"Previous qualification (grade)\",\n",
    "        # \"Admission grade\"\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# X_vif = df_cleaned.assign(const=1)\n",
    "\n",
    "# # Calculate VIF\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"Feature\"] = X_vif.columns\n",
    "# vif_data[\"VIF\"] = [\n",
    "#     variance_inflation_factor(X_vif.values, i) for i in range(len(X_vif.columns))\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Sort and Display\n",
    "# print(vif_data.sort_values(by=\"VIF\", ascending=False))\n",
    "\n",
    "# 2. Prepare Data\n",
    "X_final = df_cleaned.copy()\n",
    "X_final = sm.add_constant(X_final)\n",
    "y = df[\"Curricular units 2nd sem (grade)\"]\n",
    "\n",
    "# 3. Run OLS\n",
    "model_final = sm.OLS(y, X_final).fit()\n",
    "\n",
    "# 4. Show the World\n",
    "print(model_final.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "Sau bước này lại phát hiện thêm một biến có giá trị P|t| cao Admission grade 0.052, và với lý do nào đó mô hình bị dính vấn đề đa cộng tuyến, ở bước tiếp theo chúng tôi lại tiếp tục sử dụng kỹ thuật Backward Elimination, xóa cột Admission grade khỏi mô hình và huấn luyện lại thêm một lần nữa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.drop(\"Admission grade\", axis=1, inplace=True)\n",
    "\n",
    "# 2. Prepare Data\n",
    "X_final = df_cleaned.copy()\n",
    "X_final = sm.add_constant(X_final)\n",
    "y = df[\"Curricular units 2nd sem (grade)\"]\n",
    "\n",
    "# 3. Run OLS\n",
    "model_final = sm.OLS(y, X_final).fit()\n",
    "\n",
    "# 4. Show the World\n",
    "print(model_final.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "#### Đánh giá mô hình hồi quy tuyến tính đa biến"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "Kết quả mô hình OLS cho thấy rằng không những vấn đề đa cộng tuyến đã mất đi mà mô hình còn đơn giản hơn.Dựa trên cột coef (hệ số) từ bảng kết quả OLS, công thức dự đoán điểm học kỳ 2 (Y^) là:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Grade}_{\\text{2nd Sem}} = \\ & 0.3928 \\\\\n",
    "& - 0.4356 \\times \\text{Daytime/evening} \\\\\n",
    "& - 0.3352 \\times \\text{Debtor} \\\\\n",
    "& + 1.2187 \\times \\text{Tuition fees up to date} \\\\\n",
    "& - 0.2592 \\times \\text{Gender} \\\\\n",
    "& + 0.3222 \\times \\text{Scholarship holder} \\\\\n",
    "& + 0.8274 \\times \\text{Grade}_{\\text{1st Sem}} \\\\\n",
    "& + 0.1806 \\times \\text{Enrolled}_{\\text{2nd Sem}} \\\\\n",
    "& - 0.0313 \\times \\text{Age at enrollment} \\\\\n",
    "& + 0.0641 \\times \\text{GDP}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "- **Độ phù hợp của mô hình (Model Fit)**:\n",
    "\n",
    "    - Hệ số R2=0.717 cho thấy mô hình giải thích được 71.7% sự biến thiên của biến phụ thuộc (Điểm môn học kỳ 2). Đây là mức độ phù hợp cao và rất tốt.\n",
    "\n",
    "    - Prob (F-statistic) = 0.00: Xác nhận mô hình tổng thể có ý nghĩa thống kê và đáng tin cậy.\n",
    "\n",
    "- **Đánh giá các biến độc lập (Coefficients)**:\n",
    "\n",
    "    - Ngoại trừ hằng số (const) không có ý nghĩa thống kê (P>0.05), tất cả 9 biến độc lập còn lại đều có tác động có ý nghĩa đến kết quả (P<0.05).\n",
    "\n",
    "    - Tác động tích cực (Làm tăng điểm):\n",
    "\n",
    "        - Điểm kỳ 1 (Curricular units 1st sem): Là biến quan trọng nhất (t-stat = 82.9). Hệ số 0.827 nghĩa là điểm kỳ 1 tăng 1 đơn vị thì điểm kỳ 2 tăng tương ứng gần 0.83 điểm.\n",
    "\n",
    "        - Đóng học phí (Tuition fees up to date): Tác động rất mạnh (hệ số 1.219), sinh viên đóng học phí đầy đủ có kết quả tốt hơn hẳn.\n",
    "\n",
    "        - Số môn đăng ký kỳ 2, Học bổng, GDP: Đều có tác động dương làm tăng điểm số.\n",
    "\n",
    "    - Tác động tiêu cực (Làm giảm điểm):\n",
    "\n",
    "        - Chế độ học (Daytime/evening) và Nợ học phí (Debtor): Có tác động tiêu cực đáng kể (hệ số lần lượt là -0.43 và -0.33).\n",
    "\n",
    "        - Giới tính (Gender) và Tuổi (Age): Cũng làm giảm điểm nhẹ, người học càng lớn tuổi điểm càng có xu hướng giảm (-0.03).\n",
    "\n",
    "- **Kiểm định giả thiết (Diagnostics)**:\n",
    "\n",
    "    - Tự tương quan: Chỉ số Durbin-Watson = 2.009 (xấp xỉ 2) là lý tưởng, khẳng định không có hiện tượng tự tương quan.\n",
    "\n",
    "    - Đa cộng tuyến: Cond. No. = 217, tuy cao hơn ví dụ trước nhưng vẫn nằm trong ngưỡng chấp nhận được, không gây sai lệch nghiêm trọng.\n",
    "\n",
    "    - Phân phối chuẩn: Các chỉ số Omnibus và Jarque-Bera rất cao cho thấy phần dư không phân phối chuẩn (Skew = -1.96). Tuy nhiên, với kích thước mẫu lớn (N=4424), định lý giới hạn trung tâm giúp đảm bảo tính vững của các ước lượng hồi quy.\n",
    "\n",
    "***Kết luận***: Mô hình hoạt động rất tốt (R2>70%). Kết quả học tập kỳ 1 và việc hoàn thành nghĩa vụ học phí là những yếu tố dự báo mạnh nhất cho điểm số kỳ 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
